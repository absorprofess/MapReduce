INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1340071313_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1340071313_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1340071313_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@11d88ffd
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1340071313_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 18932; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26212420(104849680); length = 1977/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1340071313_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1340071313_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1340071313_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1340071313_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@dafe1d4
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7902d87d
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1340071313_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1340071313_0001_m_000000_0 decomp: 19924 len: 19928 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 19924 bytes from map-output for attempt_local1340071313_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 19924, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->19924
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 19888 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 19924 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 19928 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 19888 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1340071313_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1340071313_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1340071313_0001_r_000000_0' to hdfs://node01:8020/huohua/tmp/_temporary/0/task_local1340071313_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1340071313_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1340071313_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1340071313_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=40332
		FILE: Number of bytes written=659248
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=18932
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=495
		Map output records=495
		Map output bytes=18932
		Map output materialized bytes=19928
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=431
		Reduce shuffle bytes=19928
		Reduce input records=495
		Reduce output records=495
		Spilled Records=990
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=11
		Total committed heap usage (bytes)=480247808
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=18932
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1824901183_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1824901183_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1824901183_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@57a7a98f
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1824901183_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 18932; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26212420(104849680); length = 1977/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1824901183_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1824901183_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1824901183_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1824901183_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@129df58f
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@76a9a57a
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1824901183_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1824901183_0001_m_000000_0 decomp: 19924 len: 19928 to MEMORY
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1455863455_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1455863455_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1455863455_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@64b9f465
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1455863455_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 27464; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26212420(104849680); length = 1977/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1455863455_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1455863455_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1455863455_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1455863455_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 ERROR pool-6-thread-1 org.apache.hadoop.yarn.util.WindowsBasedProcessTree - ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:585)
	at org.apache.hadoop.util.Shell.run(Shell.java:482)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:776)
	at org.apache.hadoop.yarn.util.WindowsBasedProcessTree.isAvailable(WindowsBasedProcessTree.java:57)
	at org.apache.hadoop.yarn.util.ResourceCalculatorProcessTree.getResourceCalculatorProcessTree(ResourceCalculatorProcessTree.java:233)
	at org.apache.hadoop.mapred.Task.initialize(Task.java:611)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:332)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@74e4ce85
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local48240981_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local48240981_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local48240981_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2f74d091
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local48240981_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1181; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214296(104857184); length = 101/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local48240981_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local48240981_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local48240981_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local48240981_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4d7ca21b
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@d278c28
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local48240981_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local48240981_0001_m_000000_0 decomp: 1235 len: 1239 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1235 bytes from map-output for attempt_local48240981_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1235, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1235
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1195 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1235 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1239 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1195 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local48240981_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local48240981_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local48240981_0001_r_000000_0' to hdfs://node01:8020/huohua/tmp/_temporary/0/task_local48240981_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local48240981_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local48240981_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local48240981_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=2954
		FILE: Number of bytes written=596989
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=1181
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=26
		Map output records=26
		Map output bytes=1181
		Map output materialized bytes=1239
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=26
		Reduce shuffle bytes=1239
		Reduce input records=26
		Reduce output records=26
		Spilled Records=52
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=13
		Total committed heap usage (bytes)=476053504
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=1181
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local2107742586_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local2107742586_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local2107742586_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@e57c851
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local2107742586_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 18932; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26212420(104849680); length = 1977/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local2107742586_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local2107742586_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local2107742586_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local2107742586_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@36e774f9
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@23c2b555
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local2107742586_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local42673581_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local42673581_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local42673581_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2b9af3ed
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local42673581_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local360963451_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local360963451_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local360963451_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@43266048
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local360963451_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1181; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214296(104857184); length = 101/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local360963451_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local360963451_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local360963451_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local360963451_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@a332c56
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5b0705bd
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local360963451_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local360963451_0001_m_000000_0 decomp: 1235 len: 1239 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1235 bytes from map-output for attempt_local360963451_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1235, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1235
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1195 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1235 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1239 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1195 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local360963451_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local360963451_0001_r_000000_0 is allowed to commit now
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local360963451_0001_r_000000_0' to hdfs://node01:8020/huohua/tmp/_temporary/0/task_local360963451_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local360963451_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local360963451_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local360963451_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=2954
		FILE: Number of bytes written=600073
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=1181
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=26
		Map output records=26
		Map output bytes=1181
		Map output materialized bytes=1239
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=26
		Reduce shuffle bytes=1239
		Reduce input records=26
		Reduce output records=26
		Spilled Records=52
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=19
		Total committed heap usage (bytes)=449839104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=1181
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local78559096_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local78559096_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local78559096_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@18fd8dc7
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local78559096_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1181; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214296(104857184); length = 101/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local78559096_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local78559096_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local78559096_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local78559096_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4d8c7623
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@453a5a4c
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local78559096_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local78559096_0001_m_000000_0 decomp: 1235 len: 1239 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1235 bytes from map-output for attempt_local78559096_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1235, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1235
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1195 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1235 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1239 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1195 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local78559096_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local78559096_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local78559096_0001_r_000000_0' to hdfs://node01:8020/huohua/tmp/_temporary/0/task_local78559096_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local78559096_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local78559096_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local78559096_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=2954
		FILE: Number of bytes written=596989
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=1181
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=26
		Map output records=26
		Map output bytes=1181
		Map output materialized bytes=1239
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=26
		Reduce shuffle bytes=1239
		Reduce input records=26
		Reduce output records=26
		Spilled Records=52
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=17
		Total committed heap usage (bytes)=498597888
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=1181
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1207497922_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1207497922_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1207497922_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@16a3f8fd
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1207497922_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1181; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214296(104857184); length = 101/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1207497922_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1207497922_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1207497922_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1207497922_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@324991f1
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@bb54db8
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1207497922_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1207497922_0001_m_000000_0 decomp: 1235 len: 1239 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1235 bytes from map-output for attempt_local1207497922_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1235, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1235
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1195 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1235 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1239 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1195 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1207497922_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1207497922_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1207497922_0001_r_000000_0' to hdfs://node01:8020/huohua/tmp/_temporary/0/task_local1207497922_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1207497922_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1207497922_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1207497922_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=2954
		FILE: Number of bytes written=603157
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=1181
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=26
		Map output records=26
		Map output bytes=1181
		Map output materialized bytes=1239
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=26
		Reduce shuffle bytes=1239
		Reduce input records=26
		Reduce output records=26
		Spilled Records=52
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=13
		Total committed heap usage (bytes)=449839104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=1181
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1192016316_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1192016316_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1192016316_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@78a6b7c5
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1192016316_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1181; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214296(104857184); length = 101/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1192016316_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1192016316_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1192016316_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1192016316_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7aeece7
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6bf10d72
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1192016316_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1192016316_0001_m_000000_0 decomp: 1235 len: 1239 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1235 bytes from map-output for attempt_local1192016316_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1235, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1235
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1195 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1235 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1239 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1195 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1192016316_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1192016316_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1192016316_0001_r_000000_0' to hdfs://node01:8020/huohua/tmp/_temporary/0/task_local1192016316_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1192016316_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1192016316_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1192016316_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=2954
		FILE: Number of bytes written=603157
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=1181
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=26
		Map output records=26
		Map output bytes=1181
		Map output materialized bytes=1239
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=26
		Reduce shuffle bytes=1239
		Reduce input records=26
		Reduce output records=26
		Spilled Records=52
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=17
		Total committed heap usage (bytes)=497025024
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=1181
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local135503612_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local135503612_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local135503612_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2adc18b3
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local135503612_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1181; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214296(104857184); length = 101/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local135503612_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local135503612_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local135503612_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local135503612_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1c0c2e7c
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3604e894
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local135503612_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local135503612_0001_m_000000_0 decomp: 1235 len: 1239 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1235 bytes from map-output for attempt_local135503612_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1235, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1235
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1195 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1235 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1239 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1195 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local135503612_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local135503612_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local135503612_0001_r_000000_0' to hdfs://node01:8020/huohua/tmp/_temporary/0/task_local135503612_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local135503612_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local135503612_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local135503612_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=2954
		FILE: Number of bytes written=600073
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=1181
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=26
		Map output records=26
		Map output bytes=1181
		Map output materialized bytes=1239
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=26
		Reduce shuffle bytes=1239
		Reduce input records=26
		Reduce output records=26
		Spilled Records=52
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=15
		Total committed heap usage (bytes)=494403584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=1181
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1109650335_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1109650335_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1109650335_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4c668cab
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1109650335_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 18932; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26212420(104849680); length = 1977/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1109650335_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1109650335_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1109650335_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1109650335_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2881e1f4
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@65d1a2d7
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1109650335_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1109650335_0001_m_000000_0 decomp: 19924 len: 19928 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 19924 bytes from map-output for attempt_local1109650335_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 19924, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->19924
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 19888 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 19924 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 19928 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 19888 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1109650335_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1109650335_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1109650335_0001_r_000000_0' to hdfs://node01:8020/huohua/tmp/_temporary/0/task_local1109650335_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1109650335_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1109650335_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1109650335_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=40332
		FILE: Number of bytes written=659248
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=18932
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=495
		Map output records=495
		Map output bytes=18932
		Map output materialized bytes=19928
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=431
		Reduce shuffle bytes=19928
		Reduce input records=495
		Reduce output records=495
		Spilled Records=990
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=12
		Total committed heap usage (bytes)=480772096
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=18932
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local10959105_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local10959105_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local10959105_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@74873c71
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local10959105_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 27464; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26212420(104849680); length = 1977/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local10959105_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local10959105_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local10959105_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local10959105_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@722d6ab9
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2367ddbe
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local10959105_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local10959105_0001_m_000000_0 decomp: 28456 len: 28460 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 28456 bytes from map-output for attempt_local10959105_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 28456, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->28456
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 28388 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 28456 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 28460 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 28388 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1311817099_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1311817099_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1311817099_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2f74d091
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1311817099_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 27464; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26212420(104849680); length = 1977/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1311817099_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1311817099_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1311817099_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1311817099_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2555a6fb
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@349cef9d
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1311817099_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1311817099_0001_m_000000_0 decomp: 28456 len: 28460 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 28456 bytes from map-output for attempt_local1311817099_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 28456, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->28456
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 28388 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 28456 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 28460 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 28388 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1311817099_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1311817099_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1311817099_0001_r_000000_0' to hdfs://node01:8020/huohua/tmp/_temporary/0/task_local1311817099_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1311817099_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1311817099_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1311817099_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=57396
		FILE: Number of bytes written=684844
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=27464
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=495
		Map output records=495
		Map output bytes=27464
		Map output materialized bytes=28460
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=495
		Reduce shuffle bytes=28460
		Reduce input records=495
		Reduce output records=495
		Spilled Records=990
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=9
		Total committed heap usage (bytes)=546308096
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=27464
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local780593504_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local780593504_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local780593504_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@71efebab
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local780593504_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 89838; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26205936(104823744); length = 8461/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local780593504_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local780593504_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local780593504_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local780593504_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3de65192
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6f16b276
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local780593504_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local780593504_0001_m_000000_0 decomp: 94072 len: 94076 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 94072 bytes from map-output for attempt_local780593504_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 94072, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->94072
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 94032 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 94072 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 94076 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 94032 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local780593504_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local780593504_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local780593504_0001_r_000000_0' to hdfs://node01:8020/huohua/tmp/_temporary/0/task_local780593504_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local780593504_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local780593504_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local780593504_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=188628
		FILE: Number of bytes written=878568
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=89838
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=2116
		Map output records=2116
		Map output bytes=89838
		Map output materialized bytes=94076
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=1834
		Reduce shuffle bytes=94076
		Reduce input records=2116
		Reduce output records=2116
		Spilled Records=4232
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=15
		Total committed heap usage (bytes)=568852480
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=89838
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1320379375_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1320379375_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1320379375_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3db3decc
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1320379375_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 32475; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26211212(104844848); length = 3185/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1320379375_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1320379375_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1320379375_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1320379375_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1ffbe1c3
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4c63c926
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1320379375_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1320379375_0001_m_000000_0 decomp: 34071 len: 34075 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 34071 bytes from map-output for attempt_local1320379375_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 34071, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->34071
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 34032 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 34071 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 34075 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 34032 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1320379375_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1320379375_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1320379375_0001_r_000000_0' to hdfs://node01:8020/huohua/tmp/_temporary/0/task_local1320379375_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1320379375_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1320379375_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1320379375_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=68626
		FILE: Number of bytes written=701649
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=32475
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=797
		Map output records=797
		Map output bytes=32475
		Map output materialized bytes=34075
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=701
		Reduce shuffle bytes=34075
		Reduce input records=797
		Reduce output records=797
		Spilled Records=1594
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=481296384
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=32475
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local840753652_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local840753652_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local840753652_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@215f3216
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local840753652_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 90471; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26206512(104826048); length = 7885/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local840753652_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local840753652_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local840753652_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local840753652_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@46c18bf7
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4ec94cee
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local840753652_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local840753652_0001_m_000000_0 decomp: 94417 len: 94421 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 94417 bytes from map-output for attempt_local840753652_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 94417, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->94417
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 94361 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 94417 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 94421 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 94361 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local840753652_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local840753652_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local840753652_0001_r_000000_0' to hdfs://node01:8020/huohua/tmp/_temporary/0/task_local840753652_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local840753652_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local840753652_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local840753652_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=189318
		FILE: Number of bytes written=879627
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=90471
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=1972
		Map output records=1972
		Map output bytes=90471
		Map output materialized bytes=94421
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=1939
		Reduce shuffle bytes=94421
		Reduce input records=1972
		Reduce output records=1972
		Spilled Records=3944
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=479723520
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=90471
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1189583297_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1189583297_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1189583297_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1db79f0d
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1189583297_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 WARN Thread-4 org.apache.hadoop.mapred.LocalJobRunner - job_local1189583297_0001
 java.lang.Exception: java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 1
	at cn.eone.excelmapreduce.promotionplan.ExcelParser.parseExcelData(ExcelParser.java:51)
	at cn.eone.excelmapreduce.promotionplan.ExcelInputFormat$ExcelRecordReader.initialize(ExcelInputFormat.java:46)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1189583297_0001 failed with state FAILED due to: NA
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 0
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local93371660_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local93371660_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local93371660_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4c668cab
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local93371660_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 110; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local93371660_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local93371660_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local93371660_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local93371660_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@46090c61
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@513541d7
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local93371660_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local93371660_0001_m_000000_0 decomp: 114 len: 118 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 114 bytes from map-output for attempt_local93371660_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 114, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->114
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 2 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 114 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 118 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 2 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local93371660_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local93371660_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local93371660_0001_r_000000_0' to hdfs://node01:8020/huohua/tmp/_temporary/0/task_local93371660_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local93371660_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local93371660_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local93371660_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=712
		FILE: Number of bytes written=593642
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=110
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=110
		Map output materialized bytes=118
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=118
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=10
		Total committed heap usage (bytes)=481820672
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=110
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1261536365_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1261536365_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1261536365_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2f74d091
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1261536365_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 59; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1261536365_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1261536365_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1261536365_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1261536365_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1f7f5b80
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5450a99d
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1261536365_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1261536365_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 63 bytes from map-output for attempt_local1261536365_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->63
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 2 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 63 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 67 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 2 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1261536365_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1261536365_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1261536365_0001_r_000000_0' to hdfs://node01:8020/huohua/tmp/_temporary/0/task_local1261536365_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1261536365_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1261536365_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1261536365_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=610
		FILE: Number of bytes written=599657
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=59
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=59
		Map output materialized bytes=67
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=67
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=543162368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=59
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1872879263_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1872879263_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1872879263_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4c668cab
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1872879263_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 WARN Thread-4 org.apache.hadoop.mapred.LocalJobRunner - job_local1872879263_0001
 java.lang.Exception: java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 1
	at cn.eone.excelmapreduce.promotionplan.ExcelParser.parseExcelData(ExcelParser.java:51)
	at cn.eone.excelmapreduce.promotionplan.ExcelInputFormat$ExcelRecordReader.initialize(ExcelInputFormat.java:46)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1872879263_0001 failed with state FAILED due to: NA
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 0
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1628533952_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1628533952_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1628533952_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3db3decc
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1628533952_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 59; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1628533952_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1628533952_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1628533952_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1628533952_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@74a444c3
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7c642b57
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1628533952_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1628533952_0001_m_000000_0 decomp: 63 len: 67 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 63 bytes from map-output for attempt_local1628533952_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->63
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 2 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 63 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 67 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 2 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1628533952_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1628533952_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1628533952_0001_r_000000_0' to hdfs://node01:8020/huohua/tmp/_temporary/0/task_local1628533952_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1628533952_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1628533952_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1628533952_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=610
		FILE: Number of bytes written=599657
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=59
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=59
		Map output materialized bytes=67
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=67
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=12
		Total committed heap usage (bytes)=569376768
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=59
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1478197625_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1478197625_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1478197625_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1351d042
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1478197625_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1478197625_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1478197625_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1478197625_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1478197625_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@c406ebe
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1a70ee09
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1478197625_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1478197625_0001_m_000000_0 decomp: 5 len: 9 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 5 bytes from map-output for attempt_local1478197625_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 5, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->5
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 2 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 5 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 9 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 2 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1478197625_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1478197625_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1478197625_0001_r_000000_0' to hdfs://node01:8020/huohua/tmp/_temporary/0/task_local1478197625_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1478197625_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1478197625_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1478197625_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=494
		FILE: Number of bytes written=599483
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=1
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=1
		Map output materialized bytes=9
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=9
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=15
		Total committed heap usage (bytes)=481296384
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=1
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1867869202_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1867869202_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1867869202_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2f74d091
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1867869202_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1867869202_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1867869202_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1867869202_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1867869202_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@628ca466
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@712c6bfc
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1867869202_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1867869202_0001_m_000000_0 decomp: 5 len: 9 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 5 bytes from map-output for attempt_local1867869202_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 5, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->5
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 2 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 5 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 9 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 2 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1867869202_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1867869202_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1867869202_0001_r_000000_0' to hdfs://node01:8020/huohua/tmp/_temporary/0/task_local1867869202_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1867869202_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1867869202_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1867869202_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=494
		FILE: Number of bytes written=599483
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=1
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=1
		Map output materialized bytes=9
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=9
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=20
		Total committed heap usage (bytes)=479723520
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=1
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local747535789_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local747535789_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local747535789_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1db79f0d
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local747535789_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local747535789_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local747535789_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local747535789_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local747535789_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1f7f5b80
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5450a99d
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local747535789_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local747535789_0001_m_000000_0 decomp: 5 len: 9 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 5 bytes from map-output for attempt_local747535789_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 5, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->5
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 2 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 5 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 9 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 2 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local747535789_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local747535789_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local747535789_0001_r_000000_0' to hdfs://node01:8020/huohua/tmp/_temporary/0/task_local747535789_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local747535789_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local747535789_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local747535789_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=494
		FILE: Number of bytes written=596399
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=1
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=1
		Map output materialized bytes=9
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=9
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=12
		Total committed heap usage (bytes)=478674944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=1
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local584064721_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local584064721_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local584064721_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4fe91ac
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local584064721_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local584064721_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local584064721_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local584064721_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local584064721_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1212bb40
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@320ab942
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local584064721_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local584064721_0001_m_000000_0 decomp: 5 len: 9 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 5 bytes from map-output for attempt_local584064721_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 5, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->5
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 2 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 5 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 9 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 2 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local584064721_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local584064721_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local584064721_0001_r_000000_0' to hdfs://node01:8020/huohua/tmp/_temporary/0/task_local584064721_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local584064721_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local584064721_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local584064721_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=494
		FILE: Number of bytes written=596399
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=1
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=1
		Map output materialized bytes=9
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=9
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=543162368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=1
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local179123250_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local179123250_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local179123250_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@25d25bd3
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local179123250_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local179123250_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local179123250_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local179123250_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local179123250_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5e94acbb
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1df778c6
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local179123250_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local179123250_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 2 bytes from map-output for attempt_local179123250_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 6 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local179123250_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local179123250_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local179123250_0001_r_000000_0' to hdfs://node01:8020/huohua/tmp/_temporary/0/task_local179123250_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local179123250_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local179123250_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local179123250_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=488
		FILE: Number of bytes written=596390
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=22
		Total committed heap usage (bytes)=480772096
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=0
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local484920988_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local484920988_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local484920988_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@25d25bd3
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local484920988_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local484920988_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local484920988_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local484920988_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local484920988_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6bd17c5a
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@59218c54
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local484920988_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local484920988_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 2 bytes from map-output for attempt_local484920988_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 6 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local484920988_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local484920988_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local484920988_0001_r_000000_0' to hdfs://node01:8020/huohua/tmp/_temporary/0/task_local484920988_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local484920988_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local484920988_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local484920988_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=488
		FILE: Number of bytes written=596390
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=4
		Total committed heap usage (bytes)=541065216
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=0
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local402761210_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local402761210_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local402761210_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@56020846
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local402761210_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 89; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local402761210_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local402761210_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local402761210_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local402761210_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@64fa58e3
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2f21e000
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local402761210_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local402761210_0001_m_000000_0 decomp: 93 len: 97 to MEMORY
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 93 bytes from map-output for attempt_local402761210_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 93, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->93
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 2 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 93 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 97 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 2 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local402761210_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local402761210_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local402761210_0001_r_000000_0' to hdfs://node01:8020/huohua/tmp/_temporary/0/task_local402761210_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local402761210_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local402761210_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local402761210_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=670
		FILE: Number of bytes written=596663
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=89
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=89
		Map output materialized bytes=97
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=97
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=545259520
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=89
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local509458493_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local509458493_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local509458493_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@17a6d8be
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local509458493_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 90471; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26206512(104826048); length = 7885/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local509458493_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local509458493_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local509458493_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local509458493_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@49e76b19
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@140e307e
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local509458493_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local509458493_0001_m_000000_0 decomp: 94417 len: 94421 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 94417 bytes from map-output for attempt_local509458493_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 94417, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->94417
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 94361 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 94417 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 94421 bytes from disk
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 94361 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO communication thread org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO Thread-14 org.apache.hadoop.hdfs.DFSClient - Exception in createBlockOutputStream
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(Unknown Source)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSOutputStream.createSocketForPipeline(DFSOutputStream.java:1702)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.createBlockOutputStream(DFSOutputStream.java:1432)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1385)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:554)
INFO Thread-14 org.apache.hadoop.hdfs.DFSClient - Abandoning BP-1701161885-172.17.0.15-1542013829177:blk_1073757923_17101
 INFO Thread-14 org.apache.hadoop.hdfs.DFSClient - Excluding datanode DatanodeInfoWithStorage[172.17.0.14:50010,DS-d79bb498-0b85-4590-b76e-114b24fc6908,DISK]
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local509458493_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local509458493_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local509458493_0001_r_000000_0' to hdfs://node01:8020/huohua/tmp/_temporary/0/task_local509458493_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local509458493_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local509458493_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local509458493_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=189318
		FILE: Number of bytes written=879627
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=90471
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=1972
		Map output records=1972
		Map output bytes=90471
		Map output materialized bytes=94421
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=1939
		Reduce shuffle bytes=94421
		Reduce input records=1972
		Reduce output records=1972
		Spilled Records=3944
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=38
		Total committed heap usage (bytes)=387448832
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=90471
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1477719485_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1477719485_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1477719485_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@46917c79
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-26/c9a93cbc-013b-48d0-97a7-465bd538761e.xls:0+0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 ERROR LocalJobRunner Map Task Executor #0 cn.eone.excelmapreduce.advertisingreport.ExcelParser - IO Exception : File not found org.apache.poi.poifs.filesystem.NotOLE2FileException: Invalid header signature; read 0x0000000000000000, expected 0xE11AB1A1E011CFD0 - Your file appears not to be a valid OLE2 document
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1477719485_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1477719485_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1477719485_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1477719485_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3a1797ff
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@44cdfa7e
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1477719485_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1477719485_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1477719485_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 2 bytes from map-output for attempt_local1477719485_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 6 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1477719485_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1477719485_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1477719485_0001_r_000000_0' to hdfs://node01:8020/huohua/tmp/_temporary/0/task_local1477719485_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1477719485_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1477719485_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1477719485_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=440
		FILE: Number of bytes written=599458
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=0
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=7
		Total committed heap usage (bytes)=547356672
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local408745652_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local408745652_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local408745652_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@17421f84
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-26/c9a93cbc-013b-48d0-97a7-465bd538761e.xls:0+0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 ERROR LocalJobRunner Map Task Executor #0 cn.eone.excelmapreduce.advertisingreport.ExcelParser - IO Exception : File not found org.apache.poi.poifs.filesystem.NotOLE2FileException: Invalid header signature; read 0x0000000000000000, expected 0xE11AB1A1E011CFD0 - Your file appears not to be a valid OLE2 document
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local408745652_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local408745652_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local408745652_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local408745652_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@417579f0
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@163e7b92
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local408745652_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local408745652_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 2 bytes from map-output for attempt_local408745652_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 6 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local408745652_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local408745652_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local408745652_0001_r_000000_0' to hdfs://node01:8020/huohua/tmp/_temporary/0/task_local408745652_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local408745652_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local408745652_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local408745652_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local408745652_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=440
		FILE: Number of bytes written=596374
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=0
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=8
		Total committed heap usage (bytes)=546308096
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local2075116670_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local2075116670_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local2075116670_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@20b70df
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-26/c9a93cbc-013b-48d0-97a7-465bd538761e.xls:0+0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 ERROR LocalJobRunner Map Task Executor #0 cn.eone.excelmapreduce.agereport.ExcelParser - IO Exception : File not found org.apache.poi.poifs.filesystem.NotOLE2FileException: Invalid header signature; read 0x0000000000000000, expected 0xE11AB1A1E011CFD0 - Your file appears not to be a valid OLE2 document
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local2075116670_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local2075116670_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local2075116670_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local2075116670_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@488e9529
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@274f38ec
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local2075116670_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local2075116670_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 2 bytes from map-output for attempt_local2075116670_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 6 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local2075116670_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local2075116670_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local2075116670_0001_r_000000_0' to hdfs://node01:8020/huohua/tmp/_temporary/0/task_local2075116670_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local2075116670_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local2075116670_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local2075116670_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local2075116670_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=440
		FILE: Number of bytes written=599394
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=0
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=11
		Total committed heap usage (bytes)=543162368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1173376738_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1173376738_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1173376738_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7797d635
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-26/c9a93cbc-013b-48d0-97a7-465bd538761e.xls:0+0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 ERROR LocalJobRunner Map Task Executor #0 cn.eone.excelmapreduce.agereport.ExcelParser - IO Exception : File not found org.apache.poi.poifs.filesystem.NotOLE2FileException: Invalid header signature; read 0x0000000000000000, expected 0xE11AB1A1E011CFD0 - Your file appears not to be a valid OLE2 document
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1173376738_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1173376738_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1173376738_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1173376738_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3b2ce385
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@27714290
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1173376738_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1173376738_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 2 bytes from map-output for attempt_local1173376738_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 6 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1173376738_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1173376738_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1173376738_0001_r_000000_0' to hdfs://node01:8020/huohua/tmp/_temporary/0/task_local1173376738_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1173376738_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1173376738_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1173376738_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1173376738_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=440
		FILE: Number of bytes written=599394
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=0
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=541065216
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1781572666_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1781572666_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1781572666_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2b5a35b9
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/exportcampaigndata-2.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1781572666_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 50883; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26212280(104849120); length = 2117/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1781572666_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1781572666_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1781572666_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1781572666_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@34fdeb0b
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@19a2307d
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1781572666_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1781572666_0001_m_000000_0 decomp: 51945 len: 51949 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 51945 bytes from map-output for attempt_local1781572666_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 51945, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->51945
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 51851 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 51945 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 51949 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 51851 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1781572666_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1781572666_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1781572666_0001_r_000000_0' to hdfs://node01:8020/huohua/tmp/_temporary/0/task_local1781572666_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1781572666_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1781572666_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1781572666_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=104282
		FILE: Number of bytes written=755223
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=50883
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=530
		Map output records=530
		Map output bytes=50883
		Map output materialized bytes=51949
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=530
		Reduce shuffle bytes=51949
		Reduce input records=530
		Reduce output records=530
		Spilled Records=1060
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=480247808
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=50883
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local283408735_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local283408735_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local283408735_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5b4c1bc7
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/exportcampaigndata-2.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local283408735_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 50883; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26212280(104849120); length = 2117/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local283408735_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local283408735_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local283408735_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local283408735_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@44bb8623
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1b46d9bc
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local283408735_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local283408735_0001_m_000000_0 decomp: 51945 len: 51949 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 51945 bytes from map-output for attempt_local283408735_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 51945, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->51945
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 51851 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 51945 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 51949 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 51851 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local283408735_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local283408735_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local283408735_0001_r_000000_0' to hdfs://node01:8020/huohua/tmp/_temporary/0/task_local283408735_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local283408735_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local283408735_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local283408735_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=104282
		FILE: Number of bytes written=753107
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=50883
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=530
		Map output records=530
		Map output bytes=50883
		Map output materialized bytes=51949
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=530
		Reduce shuffle bytes=51949
		Reduce input records=530
		Reduce output records=530
		Spilled Records=1060
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=12
		Total committed heap usage (bytes)=595591168
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=50883
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1057408270_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1057408270_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1057408270_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@b186e6a
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/exportcampaigndata-2.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1057408270_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 50883; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26212280(104849120); length = 2117/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1057408270_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1057408270_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1057408270_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1057408270_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6e48a084
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@32e2ffec
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1057408270_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1057408270_0001_m_000000_0 decomp: 51945 len: 51949 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 51945 bytes from map-output for attempt_local1057408270_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 51945, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->51945
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 51851 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 51945 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 51949 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 51851 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1057408270_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1057408270_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1057408270_0001_r_000000_0' to hdfs://node01:8020/huohua/tmp/_temporary/0/task_local1057408270_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1057408270_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1057408270_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1057408270_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=104282
		FILE: Number of bytes written=755223
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=50883
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=530
		Map output records=530
		Map output bytes=50883
		Map output materialized bytes=51949
		Input split bytes=108
		Combine input records=0
		Combine output records=0
		Reduce input groups=530
		Reduce shuffle bytes=51949
		Reduce input records=530
		Reduce output records=530
		Spilled Records=1060
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=12
		Total committed heap usage (bytes)=478674944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=50883
 
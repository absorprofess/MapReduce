INFO main org.apache.hadoop.mapreduce.Job - Job job_local1295092535_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1295092535_0001 failed with state FAILED due to: NA
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 0
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local981572691_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local981572691_0001
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-18 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local981572691_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@21a75d88
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/EharedFriend/1.txt:0+154
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 606; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26213996(104855984); length = 401/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local981572691_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local981572691_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local981572691_0001_m_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local981572691_0001_r_000000_0
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@212707fe
 INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@459e6f24
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1318269696, maxSingleShuffleLimit=329567424, mergeThreshold=870058048, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local981572691_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local981572691_0001_m_000000_0 decomp: 810 len: 814 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 810 bytes from map-output for attempt_local981572691_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 810, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->810
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 804 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 810 bytes to disk to satisfy reduce memory limit
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 814 bytes from disk
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 804 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local981572691_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local981572691_0001_r_000000_0 is allowed to commit now
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local981572691_0001_r_000000_0' to file:/D:/EharedFriend/output/_temporary/0/task_local981572691_0001_r_000000
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local981572691_0001_r_000000_0' done.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local981572691_0001_r_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local981572691_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local981572691_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2262
		FILE: Number of bytes written=601690
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=14
		Map output records=101
		Map output bytes=606
		Map output materialized bytes=814
		Input split bytes=92
		Combine input records=0
		Combine output records=0
		Reduce input groups=50
		Reduce shuffle bytes=814
		Reduce input records=101
		Reduce output records=50
		Spilled Records=202
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=9
		Total committed heap usage (bytes)=468713472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=154
	File Output Format Counters 
		Bytes Written=3298
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local295319870_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local295319870_0001
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-18 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local295319870_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2ecfd28e
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/EharedFriend/1.txt:0+154
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 606; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26213996(104855984); length = 401/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local295319870_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local295319870_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local295319870_0001_m_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local295319870_0001_r_000000_0
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@23b12ae4
 INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@20536792
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1318269696, maxSingleShuffleLimit=329567424, mergeThreshold=870058048, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local295319870_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local295319870_0001_m_000000_0 decomp: 810 len: 814 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 810 bytes from map-output for attempt_local295319870_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 810, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->810
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 804 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 810 bytes to disk to satisfy reduce memory limit
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 814 bytes from disk
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 804 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local295319870_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local295319870_0001_r_000000_0 is allowed to commit now
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local295319870_0001_r_000000_0' to file:/D:/EharedFriend/output/_temporary/0/task_local295319870_0001_r_000000
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local295319870_0001_r_000000_0' done.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local295319870_0001_r_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local295319870_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local295319870_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2262
		FILE: Number of bytes written=601486
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=14
		Map output records=101
		Map output bytes=606
		Map output materialized bytes=814
		Input split bytes=92
		Combine input records=0
		Combine output records=0
		Reduce input groups=50
		Reduce shuffle bytes=814
		Reduce input records=101
		Reduce output records=50
		Spilled Records=202
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=7
		Total committed heap usage (bytes)=502792192
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=154
	File Output Format Counters 
		Bytes Written=3094
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local943129788_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local943129788_0001
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-18 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local943129788_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@c259b7
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/EharedFriend/1.txt:0+154
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 606; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26213996(104855984); length = 401/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local943129788_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local943129788_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local943129788_0001_m_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local943129788_0001_r_000000_0
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6a191cc5
 INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@b5c8e08
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1318269696, maxSingleShuffleLimit=329567424, mergeThreshold=870058048, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local943129788_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local943129788_0001_m_000000_0 decomp: 810 len: 814 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 810 bytes from map-output for attempt_local943129788_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 810, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->810
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 804 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 810 bytes to disk to satisfy reduce memory limit
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 814 bytes from disk
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 804 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local943129788_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local943129788_0001_r_000000_0 is allowed to commit now
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local943129788_0001_r_000000_0' to file:/D:/EharedFriend/output/_temporary/0/task_local943129788_0001_r_000000
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local943129788_0001_r_000000_0' done.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local943129788_0001_r_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local943129788_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local943129788_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2262
		FILE: Number of bytes written=601640
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=14
		Map output records=101
		Map output bytes=606
		Map output materialized bytes=814
		Input split bytes=92
		Combine input records=0
		Combine output records=0
		Reduce input groups=50
		Reduce shuffle bytes=814
		Reduce input records=101
		Reduce output records=50
		Spilled Records=202
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=8
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=154
	File Output Format Counters 
		Bytes Written=3248
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1025262928_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1025262928_0001
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-18 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1025262928_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@21a75d88
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/EharedFriend/1.txt:0+154
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 348; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214168(104856672); length = 229/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1025262928_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1025262928_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1025262928_0001_m_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1025262928_0001_r_000000_0
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4d0a46de
 INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@27e6bbfe
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1318269696, maxSingleShuffleLimit=329567424, mergeThreshold=870058048, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1025262928_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1025262928_0001_m_000000_0 decomp: 466 len: 470 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 466 bytes from map-output for attempt_local1025262928_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 466, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->466
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 460 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 466 bytes to disk to satisfy reduce memory limit
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 470 bytes from disk
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 460 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1025262928_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1025262928_0001_r_000000_0 is allowed to commit now
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1025262928_0001_r_000000_0' to file:/D:/EharedFriend/output/_temporary/0/task_local1025262928_0001_r_000000
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1025262928_0001_r_000000_0' done.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1025262928_0001_r_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1025262928_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1025262928_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1574
		FILE: Number of bytes written=601730
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=14
		Map output records=58
		Map output bytes=348
		Map output materialized bytes=470
		Input split bytes=92
		Combine input records=0
		Combine output records=0
		Reduce input groups=34
		Reduce shuffle bytes=470
		Reduce input records=58
		Reduce output records=34
		Spilled Records=116
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=9
		Total committed heap usage (bytes)=502792192
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=154
	File Output Format Counters 
		Bytes Written=1286
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local620841238_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local620841238_0001
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-18 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local620841238_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4958452b
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/EharedFriend/1.txt:0+154
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 348; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214168(104856672); length = 229/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local620841238_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local620841238_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local620841238_0001_m_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local620841238_0001_r_000000_0
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4d0a46de
 INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@27e6bbfe
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1318269696, maxSingleShuffleLimit=329567424, mergeThreshold=870058048, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local620841238_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local620841238_0001_m_000000_0 decomp: 466 len: 470 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 466 bytes from map-output for attempt_local620841238_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 466, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->466
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 460 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 466 bytes to disk to satisfy reduce memory limit
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 470 bytes from disk
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 460 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local620841238_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local620841238_0001_r_000000_0 is allowed to commit now
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local620841238_0001_r_000000_0' to file:/D:/EharedFriend/output/_temporary/0/task_local620841238_0001_r_000000
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local620841238_0001_r_000000_0' done.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local620841238_0001_r_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local620841238_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local620841238_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1574
		FILE: Number of bytes written=599750
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=14
		Map output records=58
		Map output bytes=348
		Map output materialized bytes=470
		Input split bytes=92
		Combine input records=0
		Combine output records=0
		Reduce input groups=34
		Reduce shuffle bytes=470
		Reduce input records=58
		Reduce output records=34
		Spilled Records=116
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=502792192
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=154
	File Output Format Counters 
		Bytes Written=2390
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local985411302_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local985411302_0001
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-18 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local985411302_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@759e80f8
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/EharedFriend/1.txt:0+154
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 606; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26213996(104855984); length = 401/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local985411302_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local985411302_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local985411302_0001_m_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local985411302_0001_r_000000_0
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5ff96577
 INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@9b0ec91
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1318269696, maxSingleShuffleLimit=329567424, mergeThreshold=870058048, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local985411302_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local985411302_0001_m_000000_0 decomp: 810 len: 814 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 810 bytes from map-output for attempt_local985411302_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 810, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->810
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 804 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 810 bytes to disk to satisfy reduce memory limit
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 814 bytes from disk
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 804 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local985411302_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local985411302_0001_r_000000_0 is allowed to commit now
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local985411302_0001_r_000000_0' to file:/D:/EharedFriend/output/_temporary/0/task_local985411302_0001_r_000000
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local985411302_0001_r_000000_0' done.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local985411302_0001_r_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local985411302_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local985411302_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2262
		FILE: Number of bytes written=604626
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=14
		Map output records=101
		Map output bytes=606
		Map output materialized bytes=814
		Input split bytes=92
		Combine input records=0
		Combine output records=0
		Reduce input groups=50
		Reduce shuffle bytes=814
		Reduce input records=101
		Reduce output records=50
		Spilled Records=202
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=7
		Total committed heap usage (bytes)=468713472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=154
	File Output Format Counters 
		Bytes Written=6234
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local729974911_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local729974911_0001
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-18 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local729974911_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@21a75d88
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/EharedFriend/1.txt:0+154
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 606; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26213996(104855984); length = 401/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local729974911_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local729974911_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local729974911_0001_m_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local729974911_0001_r_000000_0
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@212707fe
 INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@459e6f24
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1318269696, maxSingleShuffleLimit=329567424, mergeThreshold=870058048, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local729974911_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local729974911_0001_m_000000_0 decomp: 810 len: 814 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 810 bytes from map-output for attempt_local729974911_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 810, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->810
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 804 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 810 bytes to disk to satisfy reduce memory limit
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 814 bytes from disk
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 804 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local729974911_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local729974911_0001_r_000000_0 is allowed to commit now
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local729974911_0001_r_000000_0' to file:/D:/EharedFriend/output/_temporary/0/task_local729974911_0001_r_000000
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local729974911_0001_r_000000_0' done.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local729974911_0001_r_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local729974911_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local729974911_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2262
		FILE: Number of bytes written=598856
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=14
		Map output records=101
		Map output bytes=606
		Map output materialized bytes=814
		Input split bytes=92
		Combine input records=0
		Combine output records=0
		Reduce input groups=50
		Reduce shuffle bytes=814
		Reduce input records=101
		Reduce output records=50
		Spilled Records=202
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=468713472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=154
	File Output Format Counters 
		Bytes Written=464
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local577886503_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local577886503_0001
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-18 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local577886503_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2ecfd28e
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/EharedFriend/1.txt:0+154
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 606; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26213996(104855984); length = 401/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local577886503_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local577886503_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local577886503_0001_m_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local577886503_0001_r_000000_0
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@23b12ae4
 INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@20536792
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1318269696, maxSingleShuffleLimit=329567424, mergeThreshold=870058048, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local577886503_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local577886503_0001_m_000000_0 decomp: 810 len: 814 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 810 bytes from map-output for attempt_local577886503_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 810, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->810
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 804 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 810 bytes to disk to satisfy reduce memory limit
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 814 bytes from disk
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 804 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local577886503_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local577886503_0001_r_000000_0 is allowed to commit now
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local577886503_0001_r_000000_0' to file:/D:/EharedFriend/output/_temporary/0/task_local577886503_0001_r_000000
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local577886503_0001_r_000000_0' done.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local577886503_0001_r_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local577886503_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local577886503_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2262
		FILE: Number of bytes written=598856
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=14
		Map output records=101
		Map output bytes=606
		Map output materialized bytes=814
		Input split bytes=92
		Combine input records=0
		Combine output records=0
		Reduce input groups=50
		Reduce shuffle bytes=814
		Reduce input records=101
		Reduce output records=50
		Spilled Records=202
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=13
		Total committed heap usage (bytes)=468713472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=154
	File Output Format Counters 
		Bytes Written=464
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local299202417_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local299202417_0001
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-18 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local299202417_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4d5661f3
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/EharedFriend/1.txt:0+49
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 144; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214304(104857216); length = 93/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local299202417_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local299202417_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local299202417_0001_m_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local299202417_0001_r_000000_0
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5d004366
 INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@583c86c3
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1318269696, maxSingleShuffleLimit=329567424, mergeThreshold=870058048, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local299202417_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local299202417_0001_m_000000_0 decomp: 194 len: 198 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 194 bytes from map-output for attempt_local299202417_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 194, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->194
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 188 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 194 bytes to disk to satisfy reduce memory limit
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 198 bytes from disk
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 188 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local299202417_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local299202417_0001_r_000000_0 is allowed to commit now
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local299202417_0001_r_000000_0' to file:/D:/EharedFriend/output/_temporary/0/task_local299202417_0001_r_000000
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local299202417_0001_r_000000_0' done.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local299202417_0001_r_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local299202417_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local299202417_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=818
		FILE: Number of bytes written=596652
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=24
		Map output bytes=144
		Map output materialized bytes=198
		Input split bytes=92
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=198
		Reduce input records=24
		Reduce output records=10
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=11
		Total committed heap usage (bytes)=502792192
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=49
	File Output Format Counters 
		Bytes Written=110
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1352154343_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1352154343_0001
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-18 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1352154343_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@c259b7
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/EharedFriend/1.txt:0+37
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 60; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214360(104857440); length = 37/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1352154343_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1352154343_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1352154343_0001_m_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1352154343_0001_r_000000_0
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@433248bd
 INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1015c783
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1318269696, maxSingleShuffleLimit=329567424, mergeThreshold=870058048, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1352154343_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1352154343_0001_m_000000_0 decomp: 82 len: 86 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 82 bytes from map-output for attempt_local1352154343_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 82, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->82
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 76 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 82 bytes to disk to satisfy reduce memory limit
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 86 bytes from disk
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 76 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1352154343_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1352154343_0001_r_000000_0 is allowed to commit now
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1352154343_0001_r_000000_0' to file:/D:/EharedFriend/output/_temporary/0/task_local1352154343_0001_r_000000
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1352154343_0001_r_000000_0' done.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1352154343_0001_r_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1352154343_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1352154343_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=570
		FILE: Number of bytes written=599362
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=10
		Map output bytes=60
		Map output materialized bytes=86
		Input split bytes=92
		Combine input records=0
		Combine output records=0
		Reduce input groups=8
		Reduce shuffle bytes=86
		Reduce input records=10
		Reduce output records=8
		Spilled Records=20
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=37
	File Output Format Counters 
		Bytes Written=72
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local2063494723_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local2063494723_0001
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-18 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local2063494723_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@c259b7
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/EharedFriend/1.txt:0+154
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 228; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214172(104856688); length = 225/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local2063494723_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local2063494723_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local2063494723_0001_m_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local2063494723_0001_r_000000_0
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@433248bd
 INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1015c783
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1318269696, maxSingleShuffleLimit=329567424, mergeThreshold=870058048, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local2063494723_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local2063494723_0001_m_000000_0 decomp: 344 len: 348 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 344 bytes from map-output for attempt_local2063494723_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 344, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->344
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 340 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 344 bytes to disk to satisfy reduce memory limit
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 348 bytes from disk
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 340 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local2063494723_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local2063494723_0001_r_000000_0 is allowed to commit now
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local2063494723_0001_r_000000_0' to file:/D:/EharedFriend/output/_temporary/0/task_local2063494723_0001_r_000000
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local2063494723_0001_r_000000_0' done.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local2063494723_0001_r_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local2063494723_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local2063494723_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1330
		FILE: Number of bytes written=600246
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=14
		Map output records=57
		Map output bytes=228
		Map output materialized bytes=348
		Input split bytes=92
		Combine input records=0
		Combine output records=0
		Reduce input groups=14
		Reduce shuffle bytes=348
		Reduce input records=57
		Reduce output records=14
		Spilled Records=114
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=8
		Total committed heap usage (bytes)=502792192
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=154
	File Output Format Counters 
		Bytes Written=168
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local114470025_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local114470025_0001
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-19 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local114470025_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4958452b
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/EharedFriend/output/part-r-00000:0+156
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 WARN Thread-19 org.apache.hadoop.mapred.LocalJobRunner - job_local114470025_0001
 java.lang.Exception: java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 1
	at com.absorprofess.eharedfriend.EharedFriendTwo$EharedFriendMap.map(EharedFriendTwo.java:23)
	at com.absorprofess.eharedfriend.EharedFriendTwo$EharedFriendMap.map(EharedFriendTwo.java:17)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
INFO main org.apache.hadoop.mapreduce.Job - Job job_local114470025_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local114470025_0001 failed with state FAILED due to: NA
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 0
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local958551420_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local958551420_0001
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-19 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local958551420_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4958452b
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/EharedFriend/output/part-r-00000:0+156
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 WARN Thread-19 org.apache.hadoop.mapred.LocalJobRunner - job_local958551420_0001
 java.lang.Exception: java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 1
	at com.absorprofess.eharedfriend.EharedFriendTwo$EharedFriendMap.map(EharedFriendTwo.java:23)
	at com.absorprofess.eharedfriend.EharedFriendTwo$EharedFriendMap.map(EharedFriendTwo.java:17)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
INFO main org.apache.hadoop.mapreduce.Job - Job job_local958551420_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local958551420_0001 failed with state FAILED due to: NA
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 0
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local758291000_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local758291000_0001
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-19 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local758291000_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@759e80f8
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/EharedFriend/output/part-r-00000:0+156
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local758291000_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local758291000_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local758291000_0001_m_000000_0
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local758291000_0001_r_000000_0
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@928e3e8
 INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6e16ff35
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1318269696, maxSingleShuffleLimit=329567424, mergeThreshold=870058048, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local758291000_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local758291000_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 2 bytes from map-output for attempt_local758291000_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 6 bytes from disk
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local758291000_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local758291000_0001_r_000000_0 is allowed to commit now
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local758291000_0001_r_000000_0' to file:/D:/EharedFriend/output1/_temporary/0/task_local758291000_0001_r_000000
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local758291000_0001_r_000000_0' done.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local758291000_0001_r_000000_0
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local758291000_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local758291000_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=710
		FILE: Number of bytes written=596060
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=14
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=8
		Total committed heap usage (bytes)=502792192
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=172
	File Output Format Counters 
		Bytes Written=8
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local118665083_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local118665083_0001
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-19 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local118665083_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@759e80f8
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/EharedFriend/output/part-r-00000:0+156
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 WARN Thread-19 org.apache.hadoop.mapred.LocalJobRunner - job_local118665083_0001
 java.lang.Exception: java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 1
	at com.absorprofess.eharedfriend.EharedFriendTwo$EharedFriendMap.map(EharedFriendTwo.java:23)
	at com.absorprofess.eharedfriend.EharedFriendTwo$EharedFriendMap.map(EharedFriendTwo.java:17)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
INFO main org.apache.hadoop.mapreduce.Job - Job job_local118665083_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local118665083_0001 failed with state FAILED due to: NA
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 0
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1913594299_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1913594299_0001
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-19 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1913594299_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4958452b
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/EharedFriend/output/part-r-00000:0+156
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 WARN Thread-19 org.apache.hadoop.mapred.LocalJobRunner - job_local1913594299_0001
 java.lang.Exception: java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 1
	at com.absorprofess.eharedfriend.EharedFriendTwo$EharedFriendMap.map(EharedFriendTwo.java:23)
	at com.absorprofess.eharedfriend.EharedFriendTwo$EharedFriendMap.map(EharedFriendTwo.java:17)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1913594299_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1913594299_0001 failed with state FAILED due to: NA
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 0
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1261285211_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1261285211_0001
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-19 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1261285211_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@52beaa29
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/EharedFriend/output/part-r-00000:0+156
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1261285211_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1261285211_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1261285211_0001_m_000000_0
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1261285211_0001_r_000000_0
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@53d61926
 INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@296536ab
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1318269696, maxSingleShuffleLimit=329567424, mergeThreshold=870058048, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1261285211_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1261285211_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 2 bytes from map-output for attempt_local1261285211_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 6 bytes from disk
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1261285211_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1261285211_0001_r_000000_0 is allowed to commit now
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1261285211_0001_r_000000_0' to file:/D:/EharedFriend/output1/_temporary/0/task_local1261285211_0001_r_000000
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1261285211_0001_r_000000_0' done.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1261285211_0001_r_000000_0
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1261285211_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1261285211_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=710
		FILE: Number of bytes written=599144
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=14
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=9
		Total committed heap usage (bytes)=468713472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=172
	File Output Format Counters 
		Bytes Written=8
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1163991193_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1163991193_0001
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-19 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1163991193_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@463e91aa
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/EharedFriend/output/part-r-00000:0+156
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1163991193_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1163991193_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1163991193_0001_m_000000_0
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1163991193_0001_r_000000_0
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7a2e5fc2
 INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@59e3f4d1
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1318269696, maxSingleShuffleLimit=329567424, mergeThreshold=870058048, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1163991193_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1163991193_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 2 bytes from map-output for attempt_local1163991193_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 6 bytes from disk
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1163991193_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1163991193_0001_r_000000_0 is allowed to commit now
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1163991193_0001_r_000000_0' to file:/D:/EharedFriend/output1/_temporary/0/task_local1163991193_0001_r_000000
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1163991193_0001_r_000000_0' done.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1163991193_0001_r_000000_0
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1163991193_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1163991193_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=710
		FILE: Number of bytes written=599144
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=14
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=7
		Total committed heap usage (bytes)=468713472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=172
	File Output Format Counters 
		Bytes Written=8
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local988839850_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local988839850_0001
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-19 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local988839850_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4d5661f3
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/EharedFriend/output/part-r-00000:0+156
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local988839850_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local988839850_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local988839850_0001_m_000000_0
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local988839850_0001_r_000000_0
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@787daa60
 INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7fb06ab4
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1318269696, maxSingleShuffleLimit=329567424, mergeThreshold=870058048, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local988839850_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local988839850_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 2 bytes from map-output for attempt_local988839850_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 6 bytes from disk
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local988839850_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local988839850_0001_r_000000_0 is allowed to commit now
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local988839850_0001_r_000000_0' to file:/D:/EharedFriend/output1/_temporary/0/task_local988839850_0001_r_000000
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local988839850_0001_r_000000_0' done.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local988839850_0001_r_000000_0
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local988839850_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local988839850_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=710
		FILE: Number of bytes written=596060
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=14
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=8
		Total committed heap usage (bytes)=468713472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=172
	File Output Format Counters 
		Bytes Written=8
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1313152985_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1313152985_0001
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-19 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1313152985_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@587f2fd1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/EharedFriend/output/part-r-00000:0+156
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 WARN Thread-19 org.apache.hadoop.mapred.LocalJobRunner - job_local1313152985_0001
 java.lang.Exception: java.lang.ClassCastException: [Ljava.lang.Object; cannot be cast to [Ljava.lang.String;
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.ClassCastException: [Ljava.lang.Object; cannot be cast to [Ljava.lang.String;
	at com.absorprofess.eharedfriend.EharedFriendTwo$EharedFriendMap.map(EharedFriendTwo.java:28)
	at com.absorprofess.eharedfriend.EharedFriendTwo$EharedFriendMap.map(EharedFriendTwo.java:20)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1313152985_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1313152985_0001 failed with state FAILED due to: NA
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 0
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local481168138_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local481168138_0001
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-19 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local481168138_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7b8f6275
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/EharedFriend/output/part-r-00000:0+156
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local481168138_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local481168138_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local481168138_0001_m_000000_0
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local481168138_0001_r_000000_0
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7fee8dc6
 INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5aaa478
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1318269696, maxSingleShuffleLimit=329567424, mergeThreshold=870058048, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local481168138_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local481168138_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 2 bytes from map-output for attempt_local481168138_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 6 bytes from disk
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local481168138_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local481168138_0001_r_000000_0 is allowed to commit now
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local481168138_0001_r_000000_0' to file:/D:/EharedFriend/output1/_temporary/0/task_local481168138_0001_r_000000
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local481168138_0001_r_000000_0' done.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local481168138_0001_r_000000_0
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local481168138_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local481168138_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=710
		FILE: Number of bytes written=596060
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=14
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=468713472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=172
	File Output Format Counters 
		Bytes Written=8
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1476721935_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1476721935_0001
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-19 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1476721935_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@473c43b9
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/EharedFriend/output/part-r-00000:0+156
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 6936; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26209776(104839104); length = 4621/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1476721935_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1476721935_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1476721935_0001_m_000000_0
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1476721935_0001_r_000000_0
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4be5285
 INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@53f8e73d
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1318269696, maxSingleShuffleLimit=329567424, mergeThreshold=870058048, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1476721935_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1476721935_0001_m_000000_0 decomp: 9250 len: 9254 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 9250 bytes from map-output for attempt_local1476721935_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 9250, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->9250
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 9244 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 9250 bytes to disk to satisfy reduce memory limit
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 9254 bytes from disk
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 9244 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1476721935_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1476721935_0001_r_000000_0 is allowed to commit now
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1476721935_0001_r_000000_0' to file:/D:/EharedFriend/output1/_temporary/0/task_local1476721935_0001_r_000000
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1476721935_0001_r_000000_0' done.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1476721935_0001_r_000000_0
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1476721935_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1476721935_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=19206
		FILE: Number of bytes written=629679
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=14
		Map output records=1156
		Map output bytes=6936
		Map output materialized bytes=9254
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=91
		Reduce shuffle bytes=9254
		Reduce input records=1156
		Reduce output records=91
		Spilled Records=2312
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=7
		Total committed heap usage (bytes)=468713472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=172
	File Output Format Counters 
		Bytes Written=2799
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1866747209_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1866747209_0001
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-19 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1866747209_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@473c43b9
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/EharedFriend/output/part-r-00000:0+156
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1866747209_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1866747209_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1866747209_0001_m_000000_0
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1866747209_0001_r_000000_0
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@37ad2794
 INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5e84878b
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1318269696, maxSingleShuffleLimit=329567424, mergeThreshold=870058048, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1866747209_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1866747209_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 2 bytes from map-output for attempt_local1866747209_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 6 bytes from disk
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1866747209_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1866747209_0001_r_000000_0 is allowed to commit now
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1866747209_0001_r_000000_0' to file:/D:/EharedFriend/output1/_temporary/0/task_local1866747209_0001_r_000000
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1866747209_0001_r_000000_0' done.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1866747209_0001_r_000000_0
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1866747209_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1866747209_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=710
		FILE: Number of bytes written=599144
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=14
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=9
		Total committed heap usage (bytes)=502792192
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=172
	File Output Format Counters 
		Bytes Written=8
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local588632452_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local588632452_0001
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-19 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local588632452_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7d1a0ab5
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/EharedFriend/output/part-r-00000:0+156
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local588632452_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local588632452_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local588632452_0001_m_000000_0
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local588632452_0001_r_000000_0
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@928e3e8
 INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6e16ff35
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1318269696, maxSingleShuffleLimit=329567424, mergeThreshold=870058048, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local588632452_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local588632452_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 2 bytes from map-output for attempt_local588632452_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 6 bytes from disk
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local588632452_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local588632452_0001_r_000000_0 is allowed to commit now
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local588632452_0001_r_000000_0' to file:/D:/EharedFriend/output1/_temporary/0/task_local588632452_0001_r_000000
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local588632452_0001_r_000000_0' done.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local588632452_0001_r_000000_0
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local588632452_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local588632452_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=710
		FILE: Number of bytes written=596060
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=14
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=7
		Total committed heap usage (bytes)=468713472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=172
	File Output Format Counters 
		Bytes Written=8
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1793670651_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1793670651_0001
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-19 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1793670651_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1a54ede8
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/EharedFriend/output/part-r-00000:0+156
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 882; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26213812(104855248); length = 585/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1793670651_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1793670651_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1793670651_0001_m_000000_0
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1793670651_0001_r_000000_0
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2ec9ad10
 INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@597fc16
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1318269696, maxSingleShuffleLimit=329567424, mergeThreshold=870058048, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1793670651_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1793670651_0001_m_000000_0 decomp: 1178 len: 1182 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1178 bytes from map-output for attempt_local1793670651_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1178, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1178
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1172 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1178 bytes to disk to satisfy reduce memory limit
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1182 bytes from disk
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1172 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1793670651_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1793670651_0001_r_000000_0 is allowed to commit now
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1793670651_0001_r_000000_0' to file:/D:/EharedFriend/output1/_temporary/0/task_local1793670651_0001_r_000000
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1793670651_0001_r_000000_0' done.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1793670651_0001_r_000000_0
 INFO Thread-19 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1793670651_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1793670651_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3062
		FILE: Number of bytes written=603344
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=14
		Map output records=147
		Map output bytes=882
		Map output materialized bytes=1182
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=74
		Reduce shuffle bytes=1182
		Reduce input records=147
		Reduce output records=74
		Spilled Records=294
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=468713472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=172
	File Output Format Counters 
		Bytes Written=680
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local461745111_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local461745111_0001
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-18 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local461745111_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@64ea0735
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/data/log.txt:0+280
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 756; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214328(104857312); length = 69/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local461745111_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local461745111_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local461745111_0001_m_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local461745111_0001_r_000000_0
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@50039344
 INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@697e96d5
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1318269696, maxSingleShuffleLimit=329567424, mergeThreshold=870058048, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local461745111_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local461745111_0001_m_000000_0 decomp: 794 len: 798 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 794 bytes from map-output for attempt_local461745111_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 794, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->794
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 790 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 794 bytes to disk to satisfy reduce memory limit
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 798 bytes from disk
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 790 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local461745111_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local461745111_0001_r_000000_0 is allowed to commit now
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local461745111_0001_r_000000_0' to file:/D:/data/output/_temporary/0/task_local461745111_0001_r_000000
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local461745111_0001_r_000000_0' done.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local461745111_0001_r_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local461745111_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local461745111_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2472
		FILE: Number of bytes written=598307
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=18
		Map output records=18
		Map output bytes=756
		Map output materialized bytes=798
		Input split bytes=86
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=798
		Reduce input records=18
		Reduce output records=3
		Spilled Records=36
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=468713472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=280
	File Output Format Counters 
		Bytes Written=141
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1396490274_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1396490274_0001
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-18 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1396490274_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@32fa1638
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/data/log.txt:0+280
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 756; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214328(104857312); length = 69/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1396490274_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1396490274_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1396490274_0001_m_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1396490274_0001_r_000000_0
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@66d9e7e8
 INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2604fa26
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1318269696, maxSingleShuffleLimit=329567424, mergeThreshold=870058048, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1396490274_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1396490274_0001_m_000000_0 decomp: 794 len: 798 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 794 bytes from map-output for attempt_local1396490274_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 794, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->794
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 790 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 794 bytes to disk to satisfy reduce memory limit
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 798 bytes from disk
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 790 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1396490274_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1396490274_0001_r_000000_0 is allowed to commit now
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1396490274_0001_r_000000_0' to file:/D:/data/output/_temporary/0/task_local1396490274_0001_r_000000
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1396490274_0001_r_000000_0' done.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1396490274_0001_r_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1396490274_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1396490274_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2472
		FILE: Number of bytes written=601386
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=18
		Map output records=18
		Map output bytes=756
		Map output materialized bytes=798
		Input split bytes=86
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=798
		Reduce input records=18
		Reduce output records=3
		Spilled Records=36
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=468713472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=280
	File Output Format Counters 
		Bytes Written=136
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1955742192_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1955742192_0001
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-18 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1955742192_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3c3af554
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/data/log.txt:0+280
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 756; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214328(104857312); length = 69/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1955742192_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1955742192_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1955742192_0001_m_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1955742192_0001_r_000000_0
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5ea04188
 INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@535bc19b
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1318269696, maxSingleShuffleLimit=329567424, mergeThreshold=870058048, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1955742192_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1955742192_0001_m_000000_0 decomp: 794 len: 798 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 794 bytes from map-output for attempt_local1955742192_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 794, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->794
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 790 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 794 bytes to disk to satisfy reduce memory limit
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 798 bytes from disk
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 790 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1955742192_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1955742192_0001_r_000000_0 is allowed to commit now
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1955742192_0001_r_000000_0' to file:/D:/data/output/_temporary/0/task_local1955742192_0001_r_000000
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1955742192_0001_r_000000_0' done.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1955742192_0001_r_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1955742192_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1955742192_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2472
		FILE: Number of bytes written=601380
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=18
		Map output records=18
		Map output bytes=756
		Map output materialized bytes=798
		Input split bytes=86
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=798
		Reduce input records=18
		Reduce output records=3
		Spilled Records=36
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=502792192
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=280
	File Output Format Counters 
		Bytes Written=130
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1338241942_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1338241942_0001
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-18 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1338241942_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6b5e9911
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/data/log.txt:0+333
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 882; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214316(104857264); length = 81/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 WARN Thread-18 org.apache.hadoop.mapred.LocalJobRunner - job_local1338241942_0001
 java.lang.Exception: java.lang.NumberFormatException: For input string: ""
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.NumberFormatException: For input string: ""
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Long.parseLong(Long.java:601)
	at java.lang.Long.parseLong(Long.java:631)
	at com.absorprofess.mapreduce.WordCountMap.map(WordCountMap.java:15)
	at com.absorprofess.mapreduce.WordCountMap.map(WordCountMap.java:9)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1338241942_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1338241942_0001 failed with state FAILED due to: NA
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 0
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local2086904107_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local2086904107_0001
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-18 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local2086904107_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3c3af554
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/data/log.txt:0+333
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 882; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214316(104857264); length = 81/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 WARN Thread-18 org.apache.hadoop.mapred.LocalJobRunner - job_local2086904107_0001
 java.lang.Exception: java.lang.NumberFormatException: For input string: ""
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.NumberFormatException: For input string: ""
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Long.parseLong(Long.java:601)
	at java.lang.Long.parseLong(Long.java:631)
	at com.absorprofess.mapreduce.WordCountMap.map(WordCountMap.java:15)
	at com.absorprofess.mapreduce.WordCountMap.map(WordCountMap.java:9)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
INFO main org.apache.hadoop.mapreduce.Job - Job job_local2086904107_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local2086904107_0001 failed with state FAILED due to: NA
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 0
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local266078214_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local266078214_0001
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-18 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local266078214_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@584dcd99
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/data/log.txt:0+51
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 126; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 WARN Thread-18 org.apache.hadoop.mapred.LocalJobRunner - job_local266078214_0001
 java.lang.Exception: java.lang.NumberFormatException: For input string: ""
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.NumberFormatException: For input string: ""
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Long.parseLong(Long.java:601)
	at java.lang.Long.parseLong(Long.java:631)
	at com.absorprofess.mapreduce.WordCountMap.map(WordCountMap.java:15)
	at com.absorprofess.mapreduce.WordCountMap.map(WordCountMap.java:9)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
INFO main org.apache.hadoop.mapreduce.Job - Job job_local266078214_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local266078214_0001 failed with state FAILED due to: NA
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 0
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local327069473_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local327069473_0001
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-18 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local327069473_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@264906a9
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/data/log.txt:0+51
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 126; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 WARN Thread-18 org.apache.hadoop.mapred.LocalJobRunner - job_local327069473_0001
 java.lang.Exception: java.lang.NumberFormatException: For input string: ""
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.NumberFormatException: For input string: ""
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Long.parseLong(Long.java:601)
	at java.lang.Long.parseLong(Long.java:631)
	at com.absorprofess.mapreduce.WordCountMap.map(WordCountMap.java:16)
	at com.absorprofess.mapreduce.WordCountMap.map(WordCountMap.java:9)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
INFO main org.apache.hadoop.mapreduce.Job - Job job_local327069473_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local327069473_0001 failed with state FAILED due to: NA
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 0
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local3322938_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local3322938_0001
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-18 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local3322938_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6b5e9911
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/data/log.txt:0+45
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 126; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local3322938_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local3322938_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local3322938_0001_m_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local3322938_0001_r_000000_0
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@22e98487
 INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@458531ad
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1318269696, maxSingleShuffleLimit=329567424, mergeThreshold=870058048, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local3322938_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local3322938_0001_m_000000_0 decomp: 134 len: 138 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 134 bytes from map-output for attempt_local3322938_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 134, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->134
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 130 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 134 bytes to disk to satisfy reduce memory limit
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 138 bytes from disk
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 130 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local3322938_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local3322938_0001_r_000000_0 is allowed to commit now
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local3322938_0001_r_000000_0' to file:/D:/data/output/_temporary/0/task_local3322938_0001_r_000000
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local3322938_0001_r_000000_0' done.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local3322938_0001_r_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local3322938_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local3322938_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=678
		FILE: Number of bytes written=590085
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=3
		Map output records=3
		Map output bytes=126
		Map output materialized bytes=138
		Input split bytes=86
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=138
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=502792192
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=45
	File Output Format Counters 
		Bytes Written=71
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local24071902_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local24071902_0001
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-18 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local24071902_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@10474ecd
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/data/log.txt:0+92
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 252; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local24071902_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local24071902_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local24071902_0001_m_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local24071902_0001_r_000000_0
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3854c37e
 INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@15026a95
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1318269696, maxSingleShuffleLimit=329567424, mergeThreshold=870058048, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local24071902_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local24071902_0001_m_000000_0 decomp: 266 len: 270 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 266 bytes from map-output for attempt_local24071902_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 266, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->266
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 262 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 266 bytes to disk to satisfy reduce memory limit
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 270 bytes from disk
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 262 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local24071902_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local24071902_0001_r_000000_0 is allowed to commit now
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local24071902_0001_r_000000_0' to file:/D:/data/output/_temporary/0/task_local24071902_0001_r_000000
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local24071902_0001_r_000000_0' done.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local24071902_0001_r_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local24071902_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local24071902_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1036
		FILE: Number of bytes written=593565
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=252
		Map output materialized bytes=270
		Input split bytes=86
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=270
		Reduce input records=6
		Reduce output records=3
		Spilled Records=12
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=468713472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=92
	File Output Format Counters 
		Bytes Written=71
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local834383833_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local834383833_0001
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-18 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local834383833_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5fe8debf
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/data/log.txt:0+428
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1344; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local834383833_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local834383833_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local834383833_0001_m_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local834383833_0001_r_000000_0
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@668735b2
 INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@699c6273
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1318269696, maxSingleShuffleLimit=329567424, mergeThreshold=870058048, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local834383833_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local834383833_0001_m_000000_0 decomp: 1410 len: 1414 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1410 bytes from map-output for attempt_local834383833_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1410, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1410
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1406 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1410 bytes to disk to satisfy reduce memory limit
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1414 bytes from disk
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1406 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local834383833_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local834383833_0001_r_000000_0 is allowed to commit now
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local834383833_0001_r_000000_0' to file:/D:/data/output/_temporary/0/task_local834383833_0001_r_000000
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local834383833_0001_r_000000_0' done.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local834383833_0001_r_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local834383833_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local834383833_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=4000
		FILE: Number of bytes written=600086
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=32
		Map output records=32
		Map output bytes=1344
		Map output materialized bytes=1414
		Input split bytes=86
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=1414
		Reduce input records=32
		Reduce output records=3
		Spilled Records=64
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=468713472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=428
	File Output Format Counters 
		Bytes Written=72
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1726129263_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1726129263_0001
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-18 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1726129263_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@64ea0735
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/data/log.txt:0+428
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1344; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1726129263_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1726129263_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1726129263_0001_m_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1726129263_0001_r_000000_0
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7b733e7a
 INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@156319c0
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1318269696, maxSingleShuffleLimit=329567424, mergeThreshold=870058048, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1726129263_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1726129263_0001_m_000000_0 decomp: 1410 len: 1414 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1410 bytes from map-output for attempt_local1726129263_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1410, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1410
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1406 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1410 bytes to disk to satisfy reduce memory limit
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1414 bytes from disk
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1406 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1726129263_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1726129263_0001_r_000000_0 is allowed to commit now
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1726129263_0001_r_000000_0' to file:/D:/data/output/_temporary/0/task_local1726129263_0001_r_000000
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1726129263_0001_r_000000_0' done.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1726129263_0001_r_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1726129263_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1726129263_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=4000
		FILE: Number of bytes written=603190
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=32
		Map output records=32
		Map output bytes=1344
		Map output materialized bytes=1414
		Input split bytes=86
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=1414
		Reduce input records=32
		Reduce output records=4
		Spilled Records=64
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=468713472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=428
	File Output Format Counters 
		Bytes Written=92
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local141942492_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local141942492_0001
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-18 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local141942492_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4a7cd3ad
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/data/log.txt:0+106
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 336; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214368(104857472); length = 29/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local141942492_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local141942492_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local141942492_0001_m_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local141942492_0001_r_000000_0
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5ea04188
 INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@535bc19b
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1318269696, maxSingleShuffleLimit=329567424, mergeThreshold=870058048, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local141942492_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local141942492_0001_m_000000_0 decomp: 354 len: 358 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 354 bytes from map-output for attempt_local141942492_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 354, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->354
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 350 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 354 bytes to disk to satisfy reduce memory limit
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 358 bytes from disk
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 350 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local141942492_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local141942492_0001_r_000000_0 is allowed to commit now
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local141942492_0001_r_000000_0' to file:/D:/data/output/_temporary/0/task_local141942492_0001_r_000000
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local141942492_0001_r_000000_0' done.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local141942492_0001_r_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local141942492_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local141942492_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1240
		FILE: Number of bytes written=596935
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=8
		Map output records=8
		Map output bytes=336
		Map output materialized bytes=358
		Input split bytes=86
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=358
		Reduce input records=8
		Reduce output records=4
		Spilled Records=16
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=9
		Total committed heap usage (bytes)=468713472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=106
	File Output Format Counters 
		Bytes Written=93
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local963022692_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local963022692_0001
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-18 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local963022692_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@607f98c
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/data/log.txt:0+106
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 WARN Thread-18 org.apache.hadoop.mapred.LocalJobRunner - job_local963022692_0001
 java.lang.Exception: java.io.IOException: Type mismatch in key from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.NullWritable
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Type mismatch in key from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.NullWritable
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1074)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at com.absorprofess.mapreduce.WordCountMap.map(WordCountMap.java:17)
	at com.absorprofess.mapreduce.WordCountMap.map(WordCountMap.java:10)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
INFO main org.apache.hadoop.mapreduce.Job - Job job_local963022692_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local963022692_0001 failed with state FAILED due to: NA
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 0
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local7934004_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local7934004_0001
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-18 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local7934004_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7291c5d2
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/data/log.txt:0+104
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 WARN Thread-18 org.apache.hadoop.mapred.LocalJobRunner - job_local7934004_0001
 java.lang.Exception: java.io.IOException: Type mismatch in key from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.NullWritable
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Type mismatch in key from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.NullWritable
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1074)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at com.absorprofess.mapreduce.WordCountMap.map(WordCountMap.java:17)
	at com.absorprofess.mapreduce.WordCountMap.map(WordCountMap.java:10)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
INFO main org.apache.hadoop.mapreduce.Job - Job job_local7934004_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local7934004_0001 failed with state FAILED due to: NA
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 0
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1291260825_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1291260825_0001
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-18 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1291260825_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@607f98c
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/data/log.txt:0+104
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1291260825_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task attempt_local1291260825_0001_m_000000_0 is allowed to commit now
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1291260825_0001_m_000000_0' to file:/D:/data/output/_temporary/0/task_local1291260825_0001_m_000000
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1291260825_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1291260825_0001_m_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1291260825_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1291260825_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 15
	File System Counters
		FILE: Number of bytes read=244
		FILE: Number of bytes written=297926
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=8
		Map output records=8
		Input split bytes=86
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=128974848
	File Input Format Counters 
		Bytes Read=104
	File Output Format Counters 
		Bytes Written=126
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local2126195992_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local2126195992_0001
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-18 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local2126195992_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@587f2fd1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/data/log.txt:0+104
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 256; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214368(104857472); length = 29/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local2126195992_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local2126195992_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local2126195992_0001_m_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local2126195992_0001_r_000000_0
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4276a867
 INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@196225c2
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1318269696, maxSingleShuffleLimit=329567424, mergeThreshold=870058048, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local2126195992_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local2126195992_0001_m_000000_0 decomp: 274 len: 278 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 274 bytes from map-output for attempt_local2126195992_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 274, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->274
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 272 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 274 bytes to disk to satisfy reduce memory limit
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 278 bytes from disk
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 272 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local2126195992_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local2126195992_0001_r_000000_0 is allowed to commit now
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local2126195992_0001_r_000000_0' to file:/D:/data/output/_temporary/0/task_local2126195992_0001_r_000000
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local2126195992_0001_r_000000_0' done.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local2126195992_0001_r_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local2126195992_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local2126195992_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1076
		FILE: Number of bytes written=597332
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=8
		Map output records=8
		Map output bytes=256
		Map output materialized bytes=278
		Input split bytes=86
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=278
		Reduce input records=8
		Reduce output records=8
		Spilled Records=16
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=8
		Total committed heap usage (bytes)=502792192
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=104
	File Output Format Counters 
		Bytes Written=126
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local65665387_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local65665387_0001
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-18 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local65665387_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@724ce7d0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/data/log.txt:0+876
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 960; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214304(104857216); length = 93/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local65665387_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local65665387_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local65665387_0001_m_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local65665387_0001_r_000000_0
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@58018a1b
 INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@394c080
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1318269696, maxSingleShuffleLimit=329567424, mergeThreshold=870058048, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local65665387_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local65665387_0001_m_000000_0 decomp: 1010 len: 1014 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1010 bytes from map-output for attempt_local65665387_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1010, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1010
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1008 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1010 bytes to disk to satisfy reduce memory limit
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1014 bytes from disk
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1008 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local65665387_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local65665387_0001_r_000000_0 is allowed to commit now
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local65665387_0001_r_000000_0' to file:/D:/data/output/_temporary/0/task_local65665387_0001_r_000000
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local65665387_0001_r_000000_0' done.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local65665387_0001_r_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local65665387_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local65665387_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=4096
		FILE: Number of bytes written=593926
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=24
		Map output records=24
		Map output bytes=960
		Map output materialized bytes=1014
		Input split bytes=86
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=1014
		Reduce input records=24
		Reduce output records=24
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=468713472
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=876
	File Output Format Counters 
		Bytes Written=652
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1536522199_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1536522199_0001
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-18 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1536522199_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@21a75d88
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/data/log.txt:0+876
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1008; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214304(104857216); length = 93/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1536522199_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1536522199_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1536522199_0001_m_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1536522199_0001_r_000000_0
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@45de597a
 INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2821a461
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1318269696, maxSingleShuffleLimit=329567424, mergeThreshold=870058048, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1536522199_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1536522199_0001_m_000000_0 decomp: 1058 len: 1062 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1058 bytes from map-output for attempt_local1536522199_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1058, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1058
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1056 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1058 bytes to disk to satisfy reduce memory limit
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1062 bytes from disk
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1056 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1536522199_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1536522199_0001_r_000000_0 is allowed to commit now
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1536522199_0001_r_000000_0' to file:/D:/data/output/_temporary/0/task_local1536522199_0001_r_000000
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1536522199_0001_r_000000_0' done.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1536522199_0001_r_000000_0
 INFO Thread-18 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1536522199_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1536522199_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=4192
		FILE: Number of bytes written=600214
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=24
		Map output records=24
		Map output bytes=1008
		Map output materialized bytes=1062
		Input split bytes=86
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=1062
		Reduce input records=24
		Reduce output records=24
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=8
		Total committed heap usage (bytes)=502792192
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=876
	File Output Format Counters 
		Bytes Written=652
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Cleaning up the staging area file:/tmp/hadoop-wangyanjiao/mapred/staging/wangyanjiao1443144688/.staging/job_local1443144688_0001
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1710388759_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1710388759_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1710388759_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6b3d5bef
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1710388759_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.BlockReaderFactory - I/O error constructing remote block reader.
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3441)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385)
	at org.apache.poi.util.IOUtils.readFully(IOUtils.java:180)
	at org.apache.poi.poifs.filesystem.NPOIFSFileSystem.<init>(NPOIFSFileSystem.java:299)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:405)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:386)
	at com.absorprofess.excelmapreduce.ExcelParser.parseExcelData(ExcelParser.java:31)
	at com.absorprofess.excelmapreduce.ExcelInputFormat$ExcelRecordReader.initialize(ExcelInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Failed to connect to /172.17.0.14:50010 for block, add to deadNodes and continue. java.net.ConnectException: Connection timed out: no further information
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3441)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385)
	at org.apache.poi.util.IOUtils.readFully(IOUtils.java:180)
	at org.apache.poi.poifs.filesystem.NPOIFSFileSystem.<init>(NPOIFSFileSystem.java:299)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:405)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:386)
	at com.absorprofess.excelmapreduce.ExcelParser.parseExcelData(ExcelParser.java:31)
	at com.absorprofess.excelmapreduce.ExcelInputFormat$ExcelRecordReader.initialize(ExcelInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.BlockReaderFactory - I/O error constructing remote block reader.
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3441)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385)
	at org.apache.poi.util.IOUtils.readFully(IOUtils.java:180)
	at org.apache.poi.poifs.filesystem.NPOIFSFileSystem.<init>(NPOIFSFileSystem.java:299)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:405)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:386)
	at com.absorprofess.excelmapreduce.ExcelParser.parseExcelData(ExcelParser.java:31)
	at com.absorprofess.excelmapreduce.ExcelInputFormat$ExcelRecordReader.initialize(ExcelInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Failed to connect to /172.17.0.9:50010 for block, add to deadNodes and continue. java.net.ConnectException: Connection timed out: no further information
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3441)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385)
	at org.apache.poi.util.IOUtils.readFully(IOUtils.java:180)
	at org.apache.poi.poifs.filesystem.NPOIFSFileSystem.<init>(NPOIFSFileSystem.java:299)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:405)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:386)
	at com.absorprofess.excelmapreduce.ExcelParser.parseExcelData(ExcelParser.java:31)
	at com.absorprofess.excelmapreduce.ExcelInputFormat$ExcelRecordReader.initialize(ExcelInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.BlockReaderFactory - I/O error constructing remote block reader.
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3441)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385)
	at org.apache.poi.util.IOUtils.readFully(IOUtils.java:180)
	at org.apache.poi.poifs.filesystem.NPOIFSFileSystem.<init>(NPOIFSFileSystem.java:299)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:405)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:386)
	at com.absorprofess.excelmapreduce.ExcelParser.parseExcelData(ExcelParser.java:31)
	at com.absorprofess.excelmapreduce.ExcelInputFormat$ExcelRecordReader.initialize(ExcelInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Failed to connect to /172.17.0.15:50010 for block, add to deadNodes and continue. java.net.ConnectException: Connection timed out: no further information
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3441)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385)
	at org.apache.poi.util.IOUtils.readFully(IOUtils.java:180)
	at org.apache.poi.poifs.filesystem.NPOIFSFileSystem.<init>(NPOIFSFileSystem.java:299)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:405)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:386)
	at com.absorprofess.excelmapreduce.ExcelParser.parseExcelData(ExcelParser.java:31)
	at com.absorprofess.excelmapreduce.ExcelInputFormat$ExcelRecordReader.initialize(ExcelInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Could not obtain BP-1701161885-172.17.0.15-1542013829177:blk_1073745109_4285 from any node: java.io.IOException: No live nodes contain block BP-1701161885-172.17.0.15-1542013829177:blk_1073745109_4285 after checking nodes = [DatanodeInfoWithStorage[172.17.0.14:50010,DS-d79bb498-0b85-4590-b76e-114b24fc6908,DISK], DatanodeInfoWithStorage[172.17.0.9:50010,DS-e72e0be2-8863-44a4-8ab2-90f20c88b497,DISK], DatanodeInfoWithStorage[172.17.0.15:50010,DS-373dde89-d57c-4365-964f-cc898d9ad9a7,DISK]], ignoredNodes = null No live nodes contain current block Block locations: DatanodeInfoWithStorage[172.17.0.14:50010,DS-d79bb498-0b85-4590-b76e-114b24fc6908,DISK] DatanodeInfoWithStorage[172.17.0.9:50010,DS-e72e0be2-8863-44a4-8ab2-90f20c88b497,DISK] DatanodeInfoWithStorage[172.17.0.15:50010,DS-373dde89-d57c-4365-964f-cc898d9ad9a7,DISK] Dead nodes:  DatanodeInfoWithStorage[172.17.0.14:50010,DS-d79bb498-0b85-4590-b76e-114b24fc6908,DISK] DatanodeInfoWithStorage[172.17.0.15:50010,DS-373dde89-d57c-4365-964f-cc898d9ad9a7,DISK] DatanodeInfoWithStorage[172.17.0.9:50010,DS-e72e0be2-8863-44a4-8ab2-90f20c88b497,DISK]. Will get new block locations from namenode and retry...
 WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - DFS chooseDataNode: got # 1 IOException, will wait for 2563.842203482979 msec.
 WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.BlockReaderFactory - I/O error constructing remote block reader.
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3441)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385)
	at org.apache.poi.util.IOUtils.readFully(IOUtils.java:180)
	at org.apache.poi.poifs.filesystem.NPOIFSFileSystem.<init>(NPOIFSFileSystem.java:299)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:405)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:386)
	at com.absorprofess.excelmapreduce.ExcelParser.parseExcelData(ExcelParser.java:31)
	at com.absorprofess.excelmapreduce.ExcelInputFormat$ExcelRecordReader.initialize(ExcelInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Failed to connect to /172.17.0.15:50010 for block, add to deadNodes and continue. java.net.ConnectException: Connection timed out: no further information
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3441)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385)
	at org.apache.poi.util.IOUtils.readFully(IOUtils.java:180)
	at org.apache.poi.poifs.filesystem.NPOIFSFileSystem.<init>(NPOIFSFileSystem.java:299)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:405)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:386)
	at com.absorprofess.excelmapreduce.ExcelParser.parseExcelData(ExcelParser.java:31)
	at com.absorprofess.excelmapreduce.ExcelInputFormat$ExcelRecordReader.initialize(ExcelInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.BlockReaderFactory - I/O error constructing remote block reader.
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3441)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385)
	at org.apache.poi.util.IOUtils.readFully(IOUtils.java:180)
	at org.apache.poi.poifs.filesystem.NPOIFSFileSystem.<init>(NPOIFSFileSystem.java:299)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:405)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:386)
	at com.absorprofess.excelmapreduce.ExcelParser.parseExcelData(ExcelParser.java:31)
	at com.absorprofess.excelmapreduce.ExcelInputFormat$ExcelRecordReader.initialize(ExcelInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Failed to connect to /172.17.0.9:50010 for block, add to deadNodes and continue. java.net.ConnectException: Connection timed out: no further information
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3441)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385)
	at org.apache.poi.util.IOUtils.readFully(IOUtils.java:180)
	at org.apache.poi.poifs.filesystem.NPOIFSFileSystem.<init>(NPOIFSFileSystem.java:299)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:405)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:386)
	at com.absorprofess.excelmapreduce.ExcelParser.parseExcelData(ExcelParser.java:31)
	at com.absorprofess.excelmapreduce.ExcelInputFormat$ExcelRecordReader.initialize(ExcelInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.BlockReaderFactory - I/O error constructing remote block reader.
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3441)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385)
	at org.apache.poi.util.IOUtils.readFully(IOUtils.java:180)
	at org.apache.poi.poifs.filesystem.NPOIFSFileSystem.<init>(NPOIFSFileSystem.java:299)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:405)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:386)
	at com.absorprofess.excelmapreduce.ExcelParser.parseExcelData(ExcelParser.java:31)
	at com.absorprofess.excelmapreduce.ExcelInputFormat$ExcelRecordReader.initialize(ExcelInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Failed to connect to /172.17.0.14:50010 for block, add to deadNodes and continue. java.net.ConnectException: Connection timed out: no further information
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3441)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385)
	at org.apache.poi.util.IOUtils.readFully(IOUtils.java:180)
	at org.apache.poi.poifs.filesystem.NPOIFSFileSystem.<init>(NPOIFSFileSystem.java:299)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:405)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:386)
	at com.absorprofess.excelmapreduce.ExcelParser.parseExcelData(ExcelParser.java:31)
	at com.absorprofess.excelmapreduce.ExcelInputFormat$ExcelRecordReader.initialize(ExcelInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Could not obtain BP-1701161885-172.17.0.15-1542013829177:blk_1073745109_4285 from any node: java.io.IOException: No live nodes contain block BP-1701161885-172.17.0.15-1542013829177:blk_1073745109_4285 after checking nodes = [DatanodeInfoWithStorage[172.17.0.15:50010,DS-373dde89-d57c-4365-964f-cc898d9ad9a7,DISK], DatanodeInfoWithStorage[172.17.0.9:50010,DS-e72e0be2-8863-44a4-8ab2-90f20c88b497,DISK], DatanodeInfoWithStorage[172.17.0.14:50010,DS-d79bb498-0b85-4590-b76e-114b24fc6908,DISK]], ignoredNodes = null No live nodes contain current block Block locations: DatanodeInfoWithStorage[172.17.0.15:50010,DS-373dde89-d57c-4365-964f-cc898d9ad9a7,DISK] DatanodeInfoWithStorage[172.17.0.9:50010,DS-e72e0be2-8863-44a4-8ab2-90f20c88b497,DISK] DatanodeInfoWithStorage[172.17.0.14:50010,DS-d79bb498-0b85-4590-b76e-114b24fc6908,DISK] Dead nodes:  DatanodeInfoWithStorage[172.17.0.14:50010,DS-d79bb498-0b85-4590-b76e-114b24fc6908,DISK] DatanodeInfoWithStorage[172.17.0.15:50010,DS-373dde89-d57c-4365-964f-cc898d9ad9a7,DISK] DatanodeInfoWithStorage[172.17.0.9:50010,DS-e72e0be2-8863-44a4-8ab2-90f20c88b497,DISK]. Will get new block locations from namenode and retry...
 WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - DFS chooseDataNode: got # 2 IOException, will wait for 6208.429335015163 msec.
 WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.BlockReaderFactory - I/O error constructing remote block reader.
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3441)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385)
	at org.apache.poi.util.IOUtils.readFully(IOUtils.java:180)
	at org.apache.poi.poifs.filesystem.NPOIFSFileSystem.<init>(NPOIFSFileSystem.java:299)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:405)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:386)
	at com.absorprofess.excelmapreduce.ExcelParser.parseExcelData(ExcelParser.java:31)
	at com.absorprofess.excelmapreduce.ExcelInputFormat$ExcelRecordReader.initialize(ExcelInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Failed to connect to /172.17.0.14:50010 for block, add to deadNodes and continue. java.net.ConnectException: Connection timed out: no further information
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3441)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385)
	at org.apache.poi.util.IOUtils.readFully(IOUtils.java:180)
	at org.apache.poi.poifs.filesystem.NPOIFSFileSystem.<init>(NPOIFSFileSystem.java:299)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:405)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:386)
	at com.absorprofess.excelmapreduce.ExcelParser.parseExcelData(ExcelParser.java:31)
	at com.absorprofess.excelmapreduce.ExcelInputFormat$ExcelRecordReader.initialize(ExcelInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.BlockReaderFactory - I/O error constructing remote block reader.
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3441)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385)
	at org.apache.poi.util.IOUtils.readFully(IOUtils.java:180)
	at org.apache.poi.poifs.filesystem.NPOIFSFileSystem.<init>(NPOIFSFileSystem.java:299)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:405)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:386)
	at com.absorprofess.excelmapreduce.ExcelParser.parseExcelData(ExcelParser.java:31)
	at com.absorprofess.excelmapreduce.ExcelInputFormat$ExcelRecordReader.initialize(ExcelInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Failed to connect to /172.17.0.15:50010 for block, add to deadNodes and continue. java.net.ConnectException: Connection timed out: no further information
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3441)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385)
	at org.apache.poi.util.IOUtils.readFully(IOUtils.java:180)
	at org.apache.poi.poifs.filesystem.NPOIFSFileSystem.<init>(NPOIFSFileSystem.java:299)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:405)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:386)
	at com.absorprofess.excelmapreduce.ExcelParser.parseExcelData(ExcelParser.java:31)
	at com.absorprofess.excelmapreduce.ExcelInputFormat$ExcelRecordReader.initialize(ExcelInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.BlockReaderFactory - I/O error constructing remote block reader.
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3441)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385)
	at org.apache.poi.util.IOUtils.readFully(IOUtils.java:180)
	at org.apache.poi.poifs.filesystem.NPOIFSFileSystem.<init>(NPOIFSFileSystem.java:299)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:405)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:386)
	at com.absorprofess.excelmapreduce.ExcelParser.parseExcelData(ExcelParser.java:31)
	at com.absorprofess.excelmapreduce.ExcelInputFormat$ExcelRecordReader.initialize(ExcelInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Failed to connect to /172.17.0.9:50010 for block, add to deadNodes and continue. java.net.ConnectException: Connection timed out: no further information
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3441)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385)
	at org.apache.poi.util.IOUtils.readFully(IOUtils.java:180)
	at org.apache.poi.poifs.filesystem.NPOIFSFileSystem.<init>(NPOIFSFileSystem.java:299)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:405)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:386)
	at com.absorprofess.excelmapreduce.ExcelParser.parseExcelData(ExcelParser.java:31)
	at com.absorprofess.excelmapreduce.ExcelInputFormat$ExcelRecordReader.initialize(ExcelInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Could not obtain BP-1701161885-172.17.0.15-1542013829177:blk_1073745109_4285 from any node: java.io.IOException: No live nodes contain block BP-1701161885-172.17.0.15-1542013829177:blk_1073745109_4285 after checking nodes = [DatanodeInfoWithStorage[172.17.0.14:50010,DS-d79bb498-0b85-4590-b76e-114b24fc6908,DISK], DatanodeInfoWithStorage[172.17.0.15:50010,DS-373dde89-d57c-4365-964f-cc898d9ad9a7,DISK], DatanodeInfoWithStorage[172.17.0.9:50010,DS-e72e0be2-8863-44a4-8ab2-90f20c88b497,DISK]], ignoredNodes = null No live nodes contain current block Block locations: DatanodeInfoWithStorage[172.17.0.14:50010,DS-d79bb498-0b85-4590-b76e-114b24fc6908,DISK] DatanodeInfoWithStorage[172.17.0.15:50010,DS-373dde89-d57c-4365-964f-cc898d9ad9a7,DISK] DatanodeInfoWithStorage[172.17.0.9:50010,DS-e72e0be2-8863-44a4-8ab2-90f20c88b497,DISK] Dead nodes:  DatanodeInfoWithStorage[172.17.0.14:50010,DS-d79bb498-0b85-4590-b76e-114b24fc6908,DISK] DatanodeInfoWithStorage[172.17.0.15:50010,DS-373dde89-d57c-4365-964f-cc898d9ad9a7,DISK] DatanodeInfoWithStorage[172.17.0.9:50010,DS-e72e0be2-8863-44a4-8ab2-90f20c88b497,DISK]. Will get new block locations from namenode and retry...
 WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - DFS chooseDataNode: got # 3 IOException, will wait for 6962.032409582413 msec.
 WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.BlockReaderFactory - I/O error constructing remote block reader.
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3441)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385)
	at org.apache.poi.util.IOUtils.readFully(IOUtils.java:180)
	at org.apache.poi.poifs.filesystem.NPOIFSFileSystem.<init>(NPOIFSFileSystem.java:299)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:405)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:386)
	at com.absorprofess.excelmapreduce.ExcelParser.parseExcelData(ExcelParser.java:31)
	at com.absorprofess.excelmapreduce.ExcelInputFormat$ExcelRecordReader.initialize(ExcelInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Failed to connect to /172.17.0.9:50010 for block, add to deadNodes and continue. java.net.ConnectException: Connection timed out: no further information
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3441)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385)
	at org.apache.poi.util.IOUtils.readFully(IOUtils.java:180)
	at org.apache.poi.poifs.filesystem.NPOIFSFileSystem.<init>(NPOIFSFileSystem.java:299)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:405)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:386)
	at com.absorprofess.excelmapreduce.ExcelParser.parseExcelData(ExcelParser.java:31)
	at com.absorprofess.excelmapreduce.ExcelInputFormat$ExcelRecordReader.initialize(ExcelInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.BlockReaderFactory - I/O error constructing remote block reader.
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3441)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385)
	at org.apache.poi.util.IOUtils.readFully(IOUtils.java:180)
	at org.apache.poi.poifs.filesystem.NPOIFSFileSystem.<init>(NPOIFSFileSystem.java:299)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:405)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:386)
	at com.absorprofess.excelmapreduce.ExcelParser.parseExcelData(ExcelParser.java:31)
	at com.absorprofess.excelmapreduce.ExcelInputFormat$ExcelRecordReader.initialize(ExcelInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Failed to connect to /172.17.0.15:50010 for block, add to deadNodes and continue. java.net.ConnectException: Connection timed out: no further information
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3441)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385)
	at org.apache.poi.util.IOUtils.readFully(IOUtils.java:180)
	at org.apache.poi.poifs.filesystem.NPOIFSFileSystem.<init>(NPOIFSFileSystem.java:299)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:405)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:386)
	at com.absorprofess.excelmapreduce.ExcelParser.parseExcelData(ExcelParser.java:31)
	at com.absorprofess.excelmapreduce.ExcelInputFormat$ExcelRecordReader.initialize(ExcelInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.BlockReaderFactory - I/O error constructing remote block reader.
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3441)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385)
	at org.apache.poi.util.IOUtils.readFully(IOUtils.java:180)
	at org.apache.poi.poifs.filesystem.NPOIFSFileSystem.<init>(NPOIFSFileSystem.java:299)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:405)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:386)
	at com.absorprofess.excelmapreduce.ExcelParser.parseExcelData(ExcelParser.java:31)
	at com.absorprofess.excelmapreduce.ExcelInputFormat$ExcelRecordReader.initialize(ExcelInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Failed to connect to /172.17.0.14:50010 for block, add to deadNodes and continue. java.net.ConnectException: Connection timed out: no further information
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3441)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385)
	at org.apache.poi.util.IOUtils.readFully(IOUtils.java:180)
	at org.apache.poi.poifs.filesystem.NPOIFSFileSystem.<init>(NPOIFSFileSystem.java:299)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:405)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:386)
	at com.absorprofess.excelmapreduce.ExcelParser.parseExcelData(ExcelParser.java:31)
	at com.absorprofess.excelmapreduce.ExcelInputFormat$ExcelRecordReader.initialize(ExcelInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Could not obtain block: BP-1701161885-172.17.0.15-1542013829177:blk_1073745109_4285 file=/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls No live nodes contain current block Block locations: DatanodeInfoWithStorage[172.17.0.9:50010,DS-e72e0be2-8863-44a4-8ab2-90f20c88b497,DISK] DatanodeInfoWithStorage[172.17.0.15:50010,DS-373dde89-d57c-4365-964f-cc898d9ad9a7,DISK] DatanodeInfoWithStorage[172.17.0.14:50010,DS-d79bb498-0b85-4590-b76e-114b24fc6908,DISK] Dead nodes:  DatanodeInfoWithStorage[172.17.0.14:50010,DS-d79bb498-0b85-4590-b76e-114b24fc6908,DISK] DatanodeInfoWithStorage[172.17.0.15:50010,DS-373dde89-d57c-4365-964f-cc898d9ad9a7,DISK] DatanodeInfoWithStorage[172.17.0.9:50010,DS-e72e0be2-8863-44a4-8ab2-90f20c88b497,DISK]. Throwing a BlockMissingException
 WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Could not obtain block: BP-1701161885-172.17.0.15-1542013829177:blk_1073745109_4285 file=/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls No live nodes contain current block Block locations: DatanodeInfoWithStorage[172.17.0.9:50010,DS-e72e0be2-8863-44a4-8ab2-90f20c88b497,DISK] DatanodeInfoWithStorage[172.17.0.15:50010,DS-373dde89-d57c-4365-964f-cc898d9ad9a7,DISK] DatanodeInfoWithStorage[172.17.0.14:50010,DS-d79bb498-0b85-4590-b76e-114b24fc6908,DISK] Dead nodes:  DatanodeInfoWithStorage[172.17.0.14:50010,DS-d79bb498-0b85-4590-b76e-114b24fc6908,DISK] DatanodeInfoWithStorage[172.17.0.15:50010,DS-373dde89-d57c-4365-964f-cc898d9ad9a7,DISK] DatanodeInfoWithStorage[172.17.0.9:50010,DS-e72e0be2-8863-44a4-8ab2-90f20c88b497,DISK]. Throwing a BlockMissingException
 WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - DFS Read
 org.apache.hadoop.hdfs.BlockMissingException: Could not obtain block: BP-1701161885-172.17.0.15-1542013829177:blk_1073745109_4285 file=/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls
	at org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(DFSInputStream.java:976)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:632)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385)
	at org.apache.poi.util.IOUtils.readFully(IOUtils.java:180)
	at org.apache.poi.poifs.filesystem.NPOIFSFileSystem.<init>(NPOIFSFileSystem.java:299)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:405)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:386)
	at com.absorprofess.excelmapreduce.ExcelParser.parseExcelData(ExcelParser.java:31)
	at com.absorprofess.excelmapreduce.ExcelInputFormat$ExcelRecordReader.initialize(ExcelInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
ERROR LocalJobRunner Map Task Executor #0 com.absorprofess.excelmapreduce.ExcelParser - IO Exception : File not found org.apache.hadoop.hdfs.BlockMissingException: Could not obtain block: BP-1701161885-172.17.0.15-1542013829177:blk_1073745109_4285 file=/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1710388759_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1710388759_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1710388759_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1710388759_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@e73a59a
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@b273db3
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1710388759_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1710388759_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 2 bytes from map-output for attempt_local1710388759_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 6 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1710388759_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1710388759_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1710388759_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 WARN Thread-4 org.apache.hadoop.mapred.LocalJobRunner - job_local1710388759_0001
 java.io.FileNotFoundException: File hdfs://node01:8020/out/_temporary/0 does not exist.
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:795)
	at org.apache.hadoop.hdfs.DistributedFileSystem.access$700(DistributedFileSystem.java:106)
	at org.apache.hadoop.hdfs.DistributedFileSystem$18.doCall(DistributedFileSystem.java:853)
	at org.apache.hadoop.hdfs.DistributedFileSystem$18.doCall(DistributedFileSystem.java:849)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:860)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1517)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1557)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getAllCommittedTaskPaths(FileOutputCommitter.java:291)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:361)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:334)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:537)
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local2127234932_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local2127234932_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1710388759_0001 failed with state FAILED due to: NA
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=488
		FILE: Number of bytes written=598298
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=0
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=13
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=433061888
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local2127234932_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@27c13d84
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local2127234932_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.BlockReaderFactory - I/O error constructing remote block reader.
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3441)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385)
	at org.apache.poi.util.IOUtils.readFully(IOUtils.java:180)
	at org.apache.poi.poifs.filesystem.NPOIFSFileSystem.<init>(NPOIFSFileSystem.java:299)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:405)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:386)
	at com.absorprofess.excelmapreduce.ExcelParser.parseExcelData(ExcelParser.java:31)
	at com.absorprofess.excelmapreduce.ExcelInputFormat$ExcelRecordReader.initialize(ExcelInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Failed to connect to /172.17.0.15:50010 for block, add to deadNodes and continue. java.net.ConnectException: Connection timed out: no further information
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3441)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385)
	at org.apache.poi.util.IOUtils.readFully(IOUtils.java:180)
	at org.apache.poi.poifs.filesystem.NPOIFSFileSystem.<init>(NPOIFSFileSystem.java:299)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:405)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:386)
	at com.absorprofess.excelmapreduce.ExcelParser.parseExcelData(ExcelParser.java:31)
	at com.absorprofess.excelmapreduce.ExcelInputFormat$ExcelRecordReader.initialize(ExcelInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.BlockReaderFactory - I/O error constructing remote block reader.
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3441)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385)
	at org.apache.poi.util.IOUtils.readFully(IOUtils.java:180)
	at org.apache.poi.poifs.filesystem.NPOIFSFileSystem.<init>(NPOIFSFileSystem.java:299)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:405)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:386)
	at com.absorprofess.excelmapreduce.ExcelParser.parseExcelData(ExcelParser.java:31)
	at com.absorprofess.excelmapreduce.ExcelInputFormat$ExcelRecordReader.initialize(ExcelInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Failed to connect to /172.17.0.14:50010 for block, add to deadNodes and continue. java.net.ConnectException: Connection timed out: no further information
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3441)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385)
	at org.apache.poi.util.IOUtils.readFully(IOUtils.java:180)
	at org.apache.poi.poifs.filesystem.NPOIFSFileSystem.<init>(NPOIFSFileSystem.java:299)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:405)
	at org.apache.poi.hssf.usermodel.HSSFWorkbook.<init>(HSSFWorkbook.java:386)
	at com.absorprofess.excelmapreduce.ExcelParser.parseExcelData(ExcelParser.java:31)
	at com.absorprofess.excelmapreduce.ExcelInputFormat$ExcelRecordReader.initialize(ExcelInputFormat.java:47)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1097345522_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1097345522_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1097345522_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2666ea2b
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/data/log.txt:0+876
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1008; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214304(104857216); length = 93/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1097345522_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1097345522_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1097345522_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1097345522_0001_r_000000_0
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6230ec26
 INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6ec8d4f8
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1097345522_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1097345522_0001_m_000000_0 decomp: 1058 len: 1062 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1058 bytes from map-output for attempt_local1097345522_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1058, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1058
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1056 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1058 bytes to disk to satisfy reduce memory limit
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1062 bytes from disk
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1056 bytes
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1097345522_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1097345522_0001_r_000000_0 is allowed to commit now
 INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1097345522_0001_r_000000_0' to file:/D:/data/output/_temporary/0/task_local1097345522_0001_r_000000
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1097345522_0001_r_000000_0' done.
 INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1097345522_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1097345522_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1097345522_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=4192
		FILE: Number of bytes written=597154
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=24
		Map output records=24
		Map output bytes=1008
		Map output materialized bytes=1062
		Input split bytes=86
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=1062
		Reduce input records=24
		Reduce output records=24
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=464519168
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=876
	File Output Format Counters 
		Bytes Written=652
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1486653925_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1486653925_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1486653925_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6b6a551f
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/data/log.txt:0+876
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1486653925_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.BlockReaderFactory - I/O error constructing remote block reader.
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3441)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:144)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:184)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:556)
	at org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Failed to connect to /172.17.0.14:50010 for block, add to deadNodes and continue. java.net.ConnectException: Connection timed out: no further information
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3441)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:144)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:184)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:556)
	at org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.BlockReaderFactory - I/O error constructing remote block reader.
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3441)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:144)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:184)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:556)
	at org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Failed to connect to /172.17.0.15:50010 for block, add to deadNodes and continue. java.net.ConnectException: Connection timed out: no further information
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3441)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:144)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:184)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:556)
	at org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.BlockReaderFactory - I/O error constructing remote block reader.
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3441)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:144)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:184)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:556)
	at org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Failed to connect to /172.17.0.9:50010 for block, add to deadNodes and continue. java.net.ConnectException: Connection timed out: no further information
 java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.hdfs.DFSClient.newConnectedPeer(DFSClient.java:3441)
	at org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer(BlockReaderFactory.java:777)
	at org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp(BlockReaderFactory.java:694)
	at org.apache.hadoop.hdfs.BlockReaderFactory.build(BlockReaderFactory.java:355)
	at org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(DFSInputStream.java:665)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:874)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:926)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:144)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:184)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:556)
	at org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - Could not obtain BP-1701161885-172.17.0.15-1542013829177:blk_1073748041_7219 from any node: java.io.IOException: No live nodes contain block BP-1701161885-172.17.0.15-1542013829177:blk_1073748041_7219 after checking nodes = [DatanodeInfoWithStorage[172.17.0.14:50010,DS-d79bb498-0b85-4590-b76e-114b24fc6908,DISK], DatanodeInfoWithStorage[172.17.0.15:50010,DS-373dde89-d57c-4365-964f-cc898d9ad9a7,DISK], DatanodeInfoWithStorage[172.17.0.9:50010,DS-e72e0be2-8863-44a4-8ab2-90f20c88b497,DISK]], ignoredNodes = null No live nodes contain current block Block locations: DatanodeInfoWithStorage[172.17.0.14:50010,DS-d79bb498-0b85-4590-b76e-114b24fc6908,DISK] DatanodeInfoWithStorage[172.17.0.15:50010,DS-373dde89-d57c-4365-964f-cc898d9ad9a7,DISK] DatanodeInfoWithStorage[172.17.0.9:50010,DS-e72e0be2-8863-44a4-8ab2-90f20c88b497,DISK] Dead nodes:  DatanodeInfoWithStorage[172.17.0.14:50010,DS-d79bb498-0b85-4590-b76e-114b24fc6908,DISK] DatanodeInfoWithStorage[172.17.0.15:50010,DS-373dde89-d57c-4365-964f-cc898d9ad9a7,DISK] DatanodeInfoWithStorage[172.17.0.9:50010,DS-e72e0be2-8863-44a4-8ab2-90f20c88b497,DISK]. Will get new block locations from namenode and retry...
 WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.hdfs.DFSClient - DFS chooseDataNode: got # 1 IOException, will wait for 2340.7136175273727 msec.
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 2
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1744960391_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1744960391_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1744960391_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3e13a09c
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/data/log.txt:0+876
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1008; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214304(104857216); length = 93/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1744960391_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1744960391_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1744960391_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1744960391_0001_m_000001_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6e3c6e6a
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/data/output:0+0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1744960391_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 WARN Thread-4 org.apache.hadoop.mapred.LocalJobRunner - job_local1744960391_0001
 java.lang.Exception: java.io.FileNotFoundException: Path is not a file: /data/output
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:70)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:56)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:2157)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:2127)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:2040)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:583)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.getBlockLocations(AuthorizationProviderProxyClientProtocol.java:94)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:377)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2281)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2277)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1924)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2275)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.FileNotFoundException: Path is not a file: /data/output
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:70)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:56)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:2157)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:2127)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:2040)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:583)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.getBlockLocations(AuthorizationProviderProxyClientProtocol.java:94)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:377)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2281)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2277)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1924)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2275)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:422)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1228)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1213)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1201)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:306)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:272)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:264)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1526)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:304)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:299)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:312)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:85)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:548)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:786)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.ipc.RemoteException(java.io.FileNotFoundException): Path is not a file: /data/output
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:70)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:56)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:2157)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:2127)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:2040)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:583)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.getBlockLocations(AuthorizationProviderProxyClientProtocol.java:94)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:377)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2281)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2277)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1924)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2275)

	at org.apache.hadoop.ipc.Client.call(Client.java:1476)
	at org.apache.hadoop.ipc.Client.call(Client.java:1413)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy10.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:255)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy11.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1226)
	... 21 more
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1744960391_0001 failed with state FAILED due to: NA
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 22
	File System Counters
		FILE: Number of bytes read=261
		FILE: Number of bytes written=298371
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=876
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=24
		Map output records=24
		Map output bytes=1008
		Map output materialized bytes=1062
		Input split bytes=96
		Combine input records=0
		Spilled Records=24
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=216530944
	File Input Format Counters 
		Bytes Read=876
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1545016081_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1545016081_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1545016081_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6b6a551f
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/data/log.txt:0+876
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1008; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214304(104857216); length = 93/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1545016081_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1545016081_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1545016081_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1545016081_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@716a8cf9
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4e953398
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1545016081_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1545016081_0001_m_000000_0 decomp: 1058 len: 1062 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1058 bytes from map-output for attempt_local1545016081_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1058, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1058
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1056 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1058 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1062 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1056 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1545016081_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1545016081_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1545016081_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1545016081_0001_r_000000_0' to hdfs://node01:8020/data/output/_temporary/0/task_local1545016081_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1545016081_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1545016081_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1545016081_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=2482
		FILE: Number of bytes written=597628
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1752
		HDFS: Number of bytes written=636
		HDFS: Number of read operations=13
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Map input records=24
		Map output records=24
		Map output bytes=1008
		Map output materialized bytes=1062
		Input split bytes=96
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=1062
		Reduce input records=24
		Reduce output records=24
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=442499072
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=876
	File Output Format Counters 
		Bytes Written=636
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local2120615491_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local2120615491_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local2120615491_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@55c9409
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/data/log.txt:0+876
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1008; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214304(104857216); length = 93/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local2120615491_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local2120615491_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local2120615491_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local2120615491_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3d606b0c
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7d542d21
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local2120615491_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local2120615491_0001_m_000000_0 decomp: 1058 len: 1062 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1058 bytes from map-output for attempt_local2120615491_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1058, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1058
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1056 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1058 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1062 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1056 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local2120615491_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local2120615491_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local2120615491_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local2120615491_0001_r_000000_0' to hdfs://node01:8020/data/output/_temporary/0/task_local2120615491_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local2120615491_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local2120615491_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local2120615491_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=2482
		FILE: Number of bytes written=597628
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1752
		HDFS: Number of bytes written=636
		HDFS: Number of read operations=13
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Map input records=24
		Map output records=24
		Map output bytes=1008
		Map output materialized bytes=1062
		Input split bytes=96
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=1062
		Reduce input records=24
		Reduce output records=24
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=553648128
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=876
	File Output Format Counters 
		Bytes Written=636
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1423861468_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1423861468_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1423861468_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3e13a09c
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/data/log.txt:0+876
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1008; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214304(104857216); length = 93/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1423861468_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1423861468_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1423861468_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1423861468_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3d76e6c3
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@52a9b87b
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1423861468_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1423861468_0001_m_000000_0 decomp: 1058 len: 1062 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1058 bytes from map-output for attempt_local1423861468_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1058, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1058
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1056 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1058 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1062 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1056 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1423861468_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1423861468_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1423861468_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1423861468_0001_r_000000_0' to hdfs://node01:8020/data/output/_temporary/0/task_local1423861468_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1423861468_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1423861468_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1423861468_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=2482
		FILE: Number of bytes written=597628
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1752
		HDFS: Number of bytes written=636
		HDFS: Number of read operations=13
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Map input records=24
		Map output records=24
		Map output bytes=1008
		Map output materialized bytes=1062
		Input split bytes=96
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=1062
		Reduce input records=24
		Reduce output records=24
		Spilled Records=48
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=446693376
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=876
	File Output Format Counters 
		Bytes Written=636
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local2128443405_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local2128443405_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local2128443405_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6fde55be
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/data/log.txt:0+876
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local2128443405_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local430288790_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local430288790_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local430288790_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6b3d5bef
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local430288790_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 WARN Thread-4 org.apache.hadoop.mapred.LocalJobRunner - job_local430288790_0001
 java.lang.Exception: java.lang.ArrayIndexOutOfBoundsException: 3
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 3
	at com.absorprofess.excelmapreduce.ExcelContactCount$PhoneMapper.map(ExcelContactCount.java:30)
	at com.absorprofess.excelmapreduce.ExcelContactCount$PhoneMapper.map(ExcelContactCount.java:20)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
INFO main org.apache.hadoop.mapreduce.Job - Job job_local430288790_0001 failed with state FAILED due to: NA
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 0
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local65255362_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local65255362_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local65255362_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@25bfb40f
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local65255362_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 64; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local65255362_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local65255362_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local65255362_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local65255362_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@13541746
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@28943ea4
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local65255362_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local65255362_0001_m_000000_0 decomp: 130 len: 134 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 130 bytes from map-output for attempt_local65255362_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 130, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->130
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 127 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 130 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 134 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 127 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 WARN Thread-4 org.apache.hadoop.mapred.LocalJobRunner - job_local65255362_0001
 java.lang.Exception: java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 1
	at com.absorprofess.excelmapreduce.ExcelOutputFormat.generateFileNameForKeyValue(ExcelOutputFormat.java:64)
	at com.absorprofess.excelmapreduce.ExcelOutputFormat$MultiRecordWriter.write(ExcelOutputFormat.java:88)
	at com.absorprofess.excelmapreduce.ExcelOutputFormat$MultiRecordWriter.write(ExcelOutputFormat.java:70)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.write(ReduceTask.java:558)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.write(WrappedReducer.java:105)
	at com.absorprofess.excelmapreduce.ExcelContactCount$PhoneReducer.reduce(ExcelContactCount.java:52)
	at com.absorprofess.excelmapreduce.ExcelContactCount$PhoneReducer.reduce(ExcelContactCount.java:40)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local65255362_0001 failed with state FAILED due to: NA
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=222
		FILE: Number of bytes written=296178
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=958976
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=32
		Map output records=32
		Map output bytes=64
		Map output materialized bytes=134
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=134
		Reduce input records=0
		Reduce output records=0
		Spilled Records=32
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=7
		Total committed heap usage (bytes)=224395264
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=0
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local584915532_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local584915532_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local584915532_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3eb4e2e3
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local584915532_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 64; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local584915532_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local584915532_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local584915532_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local584915532_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@91e9a13
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@11e1b5fa
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local584915532_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local584915532_0001_m_000000_0 decomp: 130 len: 134 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 130 bytes from map-output for attempt_local584915532_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 130, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->130
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 127 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 130 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 134 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 127 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 WARN Thread-4 org.apache.hadoop.mapred.LocalJobRunner - job_local584915532_0001
 java.lang.Exception: java.lang.ArrayIndexOutOfBoundsException: 1
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 1
	at com.absorprofess.excelmapreduce.ExcelOutputFormat.generateFileNameForKeyValue(ExcelOutputFormat.java:64)
	at com.absorprofess.excelmapreduce.ExcelOutputFormat$MultiRecordWriter.write(ExcelOutputFormat.java:88)
	at com.absorprofess.excelmapreduce.ExcelOutputFormat$MultiRecordWriter.write(ExcelOutputFormat.java:70)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.write(ReduceTask.java:558)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.write(WrappedReducer.java:105)
	at com.absorprofess.excelmapreduce.ExcelContactCount$PhoneReducer.reduce(ExcelContactCount.java:52)
	at com.absorprofess.excelmapreduce.ExcelContactCount$PhoneReducer.reduce(ExcelContactCount.java:40)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
INFO main org.apache.hadoop.mapreduce.Job - Job job_local584915532_0001 failed with state FAILED due to: NA
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=222
		FILE: Number of bytes written=297724
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=958976
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=32
		Map output records=32
		Map output bytes=64
		Map output materialized bytes=134
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=134
		Reduce input records=0
		Reduce output records=0
		Spilled Records=32
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=230162432
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=0
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1030183845_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1030183845_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1030183845_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@822545
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1030183845_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 64; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1030183845_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1030183845_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1030183845_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1030183845_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@116b63b9
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@35676df2
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1030183845_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1030183845_0001_m_000000_0 decomp: 130 len: 134 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 130 bytes from map-output for attempt_local1030183845_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 130, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->130
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 127 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 130 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 134 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 127 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1030183845_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1030183845_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1030183845_0001_r_000000_0' to hdfs://node01:8020/out/_temporary/0/task_local1030183845_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1030183845_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1030183845_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1030183845_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=744
		FILE: Number of bytes written=598674
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=5
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Map input records=32
		Map output records=32
		Map output bytes=64
		Map output materialized bytes=134
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=134
		Reduce input records=32
		Reduce output records=1
		Spilled Records=64
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=487063552
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=5
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1579508617_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1579508617_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1579508617_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5c676a73
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1579508617_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 64; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1579508617_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1579508617_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1579508617_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1579508617_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@60a37f69
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7c7cda2f
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1579508617_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1579508617_0001_m_000000_0 decomp: 130 len: 134 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 130 bytes from map-output for attempt_local1579508617_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 130, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->130
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 127 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 130 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 134 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 127 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1579508617_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1579508617_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1579508617_0001_r_000000_0' to hdfs://node01:8020/out/_temporary/0/task_local1579508617_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1579508617_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1579508617_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1579508617_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=744
		FILE: Number of bytes written=598674
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=5
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Map input records=32
		Map output records=32
		Map output bytes=64
		Map output materialized bytes=134
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=134
		Reduce input records=32
		Reduce output records=1
		Spilled Records=64
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=15
		Total committed heap usage (bytes)=489160704
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=5
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1693619340_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1693619340_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1693619340_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3ff6aa6a
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1693619340_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1351; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1693619340_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1693619340_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1693619340_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1693619340_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@572f8487
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@488b8a44
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1693619340_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1693619340_0001_m_000000_0 decomp: 1417 len: 1421 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1417 bytes from map-output for attempt_local1693619340_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1417, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1417
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1384 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1417 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1421 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1384 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1693619340_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1693619340_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1693619340_0001_r_000000_0' to hdfs://node01:8020/out/_temporary/0/task_local1693619340_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1693619340_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1693619340_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1693619340_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=3318
		FILE: Number of bytes written=602535
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=1351
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Map input records=32
		Map output records=32
		Map output bytes=1351
		Map output materialized bytes=1421
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=32
		Reduce shuffle bytes=1421
		Reduce input records=32
		Reduce output records=32
		Spilled Records=64
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=553648128
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=1351
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local9901927_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local9901927_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local9901927_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3ff6aa6a
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local9901927_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1351; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local9901927_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local9901927_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local9901927_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local9901927_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3d0bd3cd
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@14ea7d39
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local9901927_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local9901927_0001_m_000000_0 decomp: 1417 len: 1421 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1417 bytes from map-output for attempt_local9901927_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1417, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1417
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1384 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1417 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1421 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1384 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local9901927_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local9901927_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local9901927_0001_r_000000_0' to hdfs://node01:8020/out/_temporary/0/task_local9901927_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local9901927_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local9901927_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local9901927_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=3318
		FILE: Number of bytes written=593259
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=1351
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Map input records=32
		Map output records=32
		Map output bytes=1351
		Map output materialized bytes=1421
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=32
		Reduce shuffle bytes=1421
		Reduce input records=32
		Reduce output records=32
		Spilled Records=64
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=484966400
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=1351
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local227387159_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local227387159_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local227387159_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5e0bc893
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local227387159_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1351; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local227387159_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local227387159_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local227387159_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local227387159_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@50932d57
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@338dcf15
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local227387159_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local227387159_0001_m_000000_0 decomp: 1417 len: 1421 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1417 bytes from map-output for attempt_local227387159_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1417, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1417
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1384 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1417 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1421 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1384 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local227387159_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local227387159_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local227387159_0001_r_000000_0' to hdfs://node01:8020/out/_temporary/0/task_local227387159_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local227387159_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local227387159_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local227387159_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=3318
		FILE: Number of bytes written=599443
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=1351
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=32
		Map output records=32
		Map output bytes=1351
		Map output materialized bytes=1421
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=32
		Reduce shuffle bytes=1421
		Reduce input records=32
		Reduce output records=32
		Spilled Records=64
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=485490688
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=1351
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1318316228_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1318316228_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1318316228_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@68d393aa
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1318316228_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1351; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1318316228_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1318316228_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1318316228_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1318316228_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@13541746
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@28943ea4
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1318316228_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1318316228_0001_m_000000_0 decomp: 1417 len: 1421 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1417 bytes from map-output for attempt_local1318316228_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1417, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1417
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1384 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1417 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1421 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1384 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 WARN Thread-4 org.apache.hadoop.mapred.LocalJobRunner - job_local1318316228_0001
 java.lang.Exception: java.lang.ArrayIndexOutOfBoundsException: 0
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 0
	at com.absorprofess.excelmapreduce.ExcelOutputFormat.generateFileNameForKeyValue(ExcelOutputFormat.java:64)
	at com.absorprofess.excelmapreduce.ExcelOutputFormat$MultiRecordWriter.write(ExcelOutputFormat.java:88)
	at com.absorprofess.excelmapreduce.ExcelOutputFormat$MultiRecordWriter.write(ExcelOutputFormat.java:70)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.write(ReduceTask.java:558)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.write(WrappedReducer.java:105)
	at com.absorprofess.excelmapreduce.ExcelContactCount$PhoneReducer.reduce(ExcelContactCount.java:31)
	at com.absorprofess.excelmapreduce.ExcelContactCount$PhoneReducer.reduce(ExcelContactCount.java:28)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1318316228_0001 failed with state FAILED due to: NA
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=222
		FILE: Number of bytes written=300557
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=958976
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=32
		Map output records=32
		Map output bytes=1351
		Map output materialized bytes=1421
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=1421
		Reduce input records=0
		Reduce output records=0
		Spilled Records=32
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=7
		Total committed heap usage (bytes)=227016704
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=0
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1473452470_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1473452470_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1473452470_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@44de53ce
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1473452470_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1351; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1473452470_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1473452470_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1473452470_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1473452470_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2da64366
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5303ad57
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1473452470_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1473452470_0001_m_000000_0 decomp: 1417 len: 1421 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1417 bytes from map-output for attempt_local1473452470_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1417, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1417
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1384 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1417 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1421 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1384 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1473452470_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1473452470_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1473452470_0001_r_000000_0' to hdfs://node01:8020/out/_temporary/0/task_local1473452470_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1473452470_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1473452470_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1473452470_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=3318
		FILE: Number of bytes written=602535
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=1351
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=32
		Map output records=32
		Map output bytes=1351
		Map output materialized bytes=1421
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=32
		Reduce shuffle bytes=1421
		Reduce input records=32
		Reduce output records=32
		Spilled Records=64
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=486539264
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=1351
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local607688794_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local607688794_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local607688794_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@44731e38
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local607688794_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1351; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local607688794_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local607688794_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local607688794_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local607688794_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2da64366
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5303ad57
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local607688794_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local607688794_0001_m_000000_0 decomp: 1417 len: 1421 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1417 bytes from map-output for attempt_local607688794_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1417, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1417
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1384 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1417 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1421 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1384 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local607688794_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local607688794_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local607688794_0001_r_000000_0' to hdfs://node01:8020/out/_temporary/0/task_local607688794_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local607688794_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local607688794_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local607688794_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=3318
		FILE: Number of bytes written=599443
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=1351
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=32
		Map output records=32
		Map output bytes=1351
		Map output materialized bytes=1421
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=32
		Reduce shuffle bytes=1421
		Reduce input records=32
		Reduce output records=32
		Spilled Records=64
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=484966400
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=1351
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1417421675_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1417421675_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1417421675_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@822545
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1417421675_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1351; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1417421675_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1417421675_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1417421675_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1417421675_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@50932d57
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@338dcf15
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1417421675_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1417421675_0001_m_000000_0 decomp: 1417 len: 1421 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1417 bytes from map-output for attempt_local1417421675_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1417, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1417
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1384 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1417 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1421 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1384 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1417421675_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1417421675_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1417421675_0001_r_000000_0' to hdfs://node01:8020/out/_temporary/0/task_local1417421675_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1417421675_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1417421675_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1417421675_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=3318
		FILE: Number of bytes written=602535
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=1351
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=32
		Map output records=32
		Map output bytes=1351
		Map output materialized bytes=1421
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=32
		Reduce shuffle bytes=1421
		Reduce input records=32
		Reduce output records=32
		Spilled Records=64
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=25
		Total committed heap usage (bytes)=483917824
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=1351
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local272615811_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local272615811_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local272615811_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4fe91ac
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local272615811_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1351; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local272615811_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local272615811_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local272615811_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local272615811_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2c357d16
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@a26b3bc
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local272615811_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local272615811_0001_m_000000_0 decomp: 1417 len: 1421 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1417 bytes from map-output for attempt_local272615811_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1417, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1417
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1384 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1417 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1421 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1384 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local272615811_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local272615811_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local272615811_0001_r_000000_0' to hdfs://node01:8020/out/_temporary/0/task_local272615811_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local272615811_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local272615811_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local272615811_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=3318
		FILE: Number of bytes written=602539
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=1351
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=32
		Map output records=32
		Map output bytes=1351
		Map output materialized bytes=1421
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=32
		Reduce shuffle bytes=1421
		Reduce input records=32
		Reduce output records=32
		Spilled Records=64
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=19
		Total committed heap usage (bytes)=435683328
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=1351
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1938212086_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1938212086_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1938212086_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@70afe0b
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1938212086_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1351; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1938212086_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1938212086_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1938212086_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1938212086_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@28bfab6c
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@71c5d627
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1938212086_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1938212086_0001_m_000000_0 decomp: 1417 len: 1421 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1417 bytes from map-output for attempt_local1938212086_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1417, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1417
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1384 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1417 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1421 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1384 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1938212086_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1938212086_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1938212086_0001_r_000000_0' to hdfs://node01:8020/out/_temporary/0/task_local1938212086_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1938212086_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1938212086_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1938212086_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=3318
		FILE: Number of bytes written=605631
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=1351
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=32
		Map output records=32
		Map output bytes=1351
		Map output materialized bytes=1421
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=32
		Reduce shuffle bytes=1421
		Reduce input records=32
		Reduce output records=32
		Spilled Records=64
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=543162368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=1351
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local783649557_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local783649557_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local783649557_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7578c421
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local783649557_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1351; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local783649557_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local783649557_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local783649557_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local783649557_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@75580bb2
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@752a62fd
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local783649557_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local783649557_0001_m_000000_0 decomp: 1417 len: 1421 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1417 bytes from map-output for attempt_local783649557_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1417, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1417
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1384 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1417 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1421 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1384 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local783649557_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local783649557_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local783649557_0001_r_000000_0' to hdfs://node01:8020/out/_temporary/0/task_local783649557_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local783649557_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local783649557_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local783649557_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=3318
		FILE: Number of bytes written=602375
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=1351
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=32
		Map output records=32
		Map output bytes=1351
		Map output materialized bytes=1421
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=32
		Reduce shuffle bytes=1421
		Reduce input records=32
		Reduce output records=32
		Spilled Records=64
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=17
		Total committed heap usage (bytes)=481296384
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=1351
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local264317661_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local264317661_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local264317661_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@44d895e5
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local264317661_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1351; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local264317661_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local264317661_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local264317661_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local264317661_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@62f81b3c
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3309866e
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local264317661_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local264317661_0001_m_000000_0 decomp: 1417 len: 1421 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1417 bytes from map-output for attempt_local264317661_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1417, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1417
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1384 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1417 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1421 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1384 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local264317661_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local264317661_0001_r_000000_0 is allowed to commit now
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local264317661_0001_r_000000_0' to hdfs://node01:8020/out/_temporary/0/task_local264317661_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local264317661_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local264317661_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local264317661_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=3318
		FILE: Number of bytes written=602375
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=1351
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=32
		Map output records=32
		Map output bytes=1351
		Map output materialized bytes=1421
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=32
		Reduce shuffle bytes=1421
		Reduce input records=32
		Reduce output records=32
		Spilled Records=64
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=543162368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=1351
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local877596229_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local877596229_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local877596229_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6f47c9fc
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local877596229_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1175; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local877596229_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local877596229_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local877596229_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local877596229_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2881e1f4
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@65d1a2d7
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local877596229_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local877596229_0001_m_000000_0 decomp: 1241 len: 1245 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1241 bytes from map-output for attempt_local877596229_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1241, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1241
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1214 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1241 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1245 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1214 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local877596229_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local877596229_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local877596229_0001_r_000000_0' to hdfs://node01:8020/out/_temporary/0/task_local877596229_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local877596229_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local877596229_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local877596229_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=2966
		FILE: Number of bytes written=601847
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=1175
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=32
		Map output records=32
		Map output bytes=1175
		Map output materialized bytes=1245
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=32
		Reduce shuffle bytes=1245
		Reduce input records=32
		Reduce output records=32
		Spilled Records=64
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=10
		Total committed heap usage (bytes)=478674944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=1175
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local377393713_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local377393713_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local377393713_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@25cbc5ab
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local377393713_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1383; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local377393713_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local377393713_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local377393713_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local377393713_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7fede793
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@49375045
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local377393713_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local377393713_0001_m_000000_0 decomp: 1449 len: 1453 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1449 bytes from map-output for attempt_local377393713_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1449, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1449
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1416 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1449 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1453 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1416 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local377393713_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local377393713_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local377393713_0001_r_000000_0' to hdfs://node01:8020/out/_temporary/0/task_local377393713_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local377393713_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local377393713_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local377393713_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=3382
		FILE: Number of bytes written=602471
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=1383
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=32
		Map output records=32
		Map output bytes=1383
		Map output materialized bytes=1453
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=32
		Reduce shuffle bytes=1453
		Reduce input records=32
		Reduce output records=32
		Spilled Records=64
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=12
		Total committed heap usage (bytes)=478674944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=1383
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local840452019_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local840452019_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local840452019_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@545ebfad
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local840452019_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1223; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local840452019_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local840452019_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local840452019_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local840452019_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2881e1f4
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@65d1a2d7
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local840452019_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local840452019_0001_m_000000_0 decomp: 1289 len: 1293 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1289 bytes from map-output for attempt_local840452019_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1289, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1289
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1262 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1289 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1293 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1262 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local840452019_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local840452019_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local840452019_0001_r_000000_0' to hdfs://node01:8020/out/_temporary/0/task_local840452019_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local840452019_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local840452019_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local840452019_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=3062
		FILE: Number of bytes written=601991
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=1223
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=32
		Map output records=32
		Map output bytes=1223
		Map output materialized bytes=1293
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=32
		Reduce shuffle bytes=1293
		Reduce input records=32
		Reduce output records=32
		Spilled Records=64
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=25
		Total committed heap usage (bytes)=568852480
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=1223
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1392284094_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1392284094_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1392284094_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7ec99085
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1392284094_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1217; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1392284094_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1392284094_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1392284094_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1392284094_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@62f81b3c
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3309866e
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1392284094_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1392284094_0001_m_000000_0 decomp: 1283 len: 1287 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1283 bytes from map-output for attempt_local1392284094_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1283, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1283
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1256 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1283 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1287 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1256 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1392284094_0001_r_000000_0 is done. And is in the process of committing
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1392284094_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1392284094_0001_r_000000_0' to hdfs://node01:8020/out/_temporary/0/task_local1392284094_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1392284094_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1392284094_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1392284094_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=3050
		FILE: Number of bytes written=605065
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=1217
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=32
		Map output records=32
		Map output bytes=1217
		Map output materialized bytes=1287
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=32
		Reduce shuffle bytes=1287
		Reduce input records=32
		Reduce output records=32
		Spilled Records=64
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=11
		Total committed heap usage (bytes)=479723520
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=1217
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1938008713_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1938008713_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1938008713_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@20a44367
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1938008713_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1223; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1938008713_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1938008713_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1938008713_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1938008713_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2299825a
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2dfa427a
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1938008713_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1938008713_0001_m_000000_0 decomp: 1289 len: 1293 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1289 bytes from map-output for attempt_local1938008713_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1289, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1289
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1262 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1289 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1293 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1262 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1938008713_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1938008713_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1938008713_0001_r_000000_0' to hdfs://node01:8020/out/_temporary/0/task_local1938008713_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1938008713_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1938008713_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1938008713_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=3062
		FILE: Number of bytes written=605083
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=1223
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=32
		Map output records=32
		Map output bytes=1223
		Map output materialized bytes=1293
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=32
		Reduce shuffle bytes=1293
		Reduce input records=32
		Reduce output records=32
		Spilled Records=64
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=11
		Total committed heap usage (bytes)=546308096
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=1223
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1875038467_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1875038467_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1875038467_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5faae794
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1875038467_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1875038467_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1875038467_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1875038467_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1875038467_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@36515b41
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6c4a2710
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1875038467_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1875038467_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 2 bytes from map-output for attempt_local1875038467_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 6 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1875038467_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1875038467_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1875038467_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1875038467_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=488
		FILE: Number of bytes written=601222
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=13
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=480772096
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=0
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local650144534_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local650144534_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local650144534_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@44d895e5
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local650144534_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1191; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local650144534_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local650144534_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local650144534_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local650144534_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@62f81b3c
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3309866e
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local650144534_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local650144534_0001_m_000000_0 decomp: 1257 len: 1261 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1257 bytes from map-output for attempt_local650144534_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1257, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1257
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1231 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1257 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1261 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1231 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local650144534_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local650144534_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local650144534_0001_r_000000_0' to hdfs://node01:8020/out/_temporary/0/task_local650144534_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local650144534_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local650144534_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local650144534_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=2998
		FILE: Number of bytes written=601895
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=1191
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=32
		Map output records=32
		Map output bytes=1191
		Map output materialized bytes=1261
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=32
		Reduce shuffle bytes=1261
		Reduce input records=32
		Reduce output records=32
		Spilled Records=64
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=8
		Total committed heap usage (bytes)=546308096
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=1191
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1258129457_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1258129457_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1258129457_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@44d895e5
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1258129457_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1191; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1258129457_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1258129457_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1258129457_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1258129457_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@71930a8c
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@56b456ac
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1258129457_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1258129457_0001_m_000000_0 decomp: 1257 len: 1261 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1257 bytes from map-output for attempt_local1258129457_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1257, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1257
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1231 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1257 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1261 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1231 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1258129457_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1258129457_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1258129457_0001_r_000000_0' to hdfs://node01:8020/out/_temporary/0/task_local1258129457_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1258129457_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1258129457_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1258129457_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=2998
		FILE: Number of bytes written=604987
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=1191
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=32
		Map output records=32
		Map output bytes=1191
		Map output materialized bytes=1261
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=32
		Reduce shuffle bytes=1261
		Reduce input records=32
		Reduce output records=32
		Spilled Records=64
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=10
		Total committed heap usage (bytes)=481296384
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=1191
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local517609242_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local517609242_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local517609242_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3c632153
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local517609242_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 843; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214296(104857184); length = 101/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local517609242_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local517609242_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local517609242_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local517609242_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5022082f
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6c6fa144
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local517609242_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local517609242_0001_m_000000_0 decomp: 897 len: 901 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 897 bytes from map-output for attempt_local517609242_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 897, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->897
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 871 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 897 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 901 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 871 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local517609242_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local517609242_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local517609242_0001_r_000000_0' to hdfs://node01:8020/out/_temporary/0/task_local517609242_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local517609242_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local517609242_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local517609242_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=2278
		FILE: Number of bytes written=600815
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=843
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=26
		Map output records=26
		Map output bytes=843
		Map output materialized bytes=901
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=26
		Reduce shuffle bytes=901
		Reduce input records=26
		Reduce output records=26
		Spilled Records=52
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=544210944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=843
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local20429814_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local20429814_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local20429814_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5faae794
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local20429814_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 889; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214292(104857168); length = 105/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local20429814_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local20429814_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local20429814_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local20429814_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@75580bb2
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@752a62fd
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local20429814_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local20429814_0001_m_000000_0 decomp: 945 len: 949 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 945 bytes from map-output for attempt_local20429814_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 945, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->945
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 919 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 945 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 949 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 919 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local20429814_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local20429814_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local20429814_0001_r_000000_0' to hdfs://node01:8020/out/_temporary/0/task_local20429814_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local20429814_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local20429814_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local20429814_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=2374
		FILE: Number of bytes written=597867
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=889
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=27
		Map output records=27
		Map output bytes=889
		Map output materialized bytes=949
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=27
		Reduce shuffle bytes=949
		Reduce input records=27
		Reduce output records=27
		Spilled Records=54
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=11
		Total committed heap usage (bytes)=478674944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=889
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1783406414_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1783406414_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1783406414_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@44d895e5
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1783406414_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1159; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214272(104857088); length = 125/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1783406414_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1783406414_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1783406414_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1783406414_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@62f81b3c
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3309866e
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1783406414_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1783406414_0001_m_000000_0 decomp: 1225 len: 1229 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1225 bytes from map-output for attempt_local1783406414_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1225, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1225
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1199 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1225 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1229 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1199 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1783406414_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1783406414_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1783406414_0001_r_000000_0' to hdfs://node01:8020/out/_temporary/0/task_local1783406414_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1783406414_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1783406414_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1783406414_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=2934
		FILE: Number of bytes written=604891
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=1159
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=32
		Map output records=32
		Map output bytes=1159
		Map output materialized bytes=1229
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=32
		Reduce shuffle bytes=1229
		Reduce input records=32
		Reduce output records=32
		Spilled Records=64
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=12
		Total committed heap usage (bytes)=478150656
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=1159
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1363843864_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1363843864_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1363843864_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@397e7dd8
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1363843864_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 843; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214296(104857184); length = 101/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1363843864_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1363843864_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1363843864_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1363843864_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@46c18bf7
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4ec94cee
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1363843864_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1363843864_0001_m_000000_0 decomp: 897 len: 901 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 897 bytes from map-output for attempt_local1363843864_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 897, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->897
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 871 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 897 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 901 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 871 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1363843864_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1363843864_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1363843864_0001_r_000000_0' to hdfs://node01:8020/out/_temporary/0/task_local1363843864_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1363843864_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1363843864_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1363843864_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=2278
		FILE: Number of bytes written=603907
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=843
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=26
		Map output records=26
		Map output bytes=843
		Map output materialized bytes=901
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=26
		Reduce shuffle bytes=901
		Reduce input records=26
		Reduce output records=26
		Spilled Records=52
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=544210944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=843
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local942127170_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local942127170_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local942127170_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@b312f2b
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local942127170_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 843; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214296(104857184); length = 101/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local942127170_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local942127170_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local942127170_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local942127170_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4ff3dde3
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1a77d441
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local942127170_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local942127170_0001_m_000000_0 decomp: 897 len: 901 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 897 bytes from map-output for attempt_local942127170_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 897, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->897
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 871 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 897 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 901 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 871 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local942127170_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local942127170_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local942127170_0001_r_000000_0' to hdfs://node01:8020/out/_temporary/0/task_local942127170_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local942127170_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local942127170_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local942127170_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=2278
		FILE: Number of bytes written=600815
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=843
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=26
		Map output records=26
		Map output bytes=843
		Map output materialized bytes=901
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=26
		Reduce shuffle bytes=901
		Reduce input records=26
		Reduce output records=26
		Spilled Records=52
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=13
		Total committed heap usage (bytes)=482344960
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=843
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1526046932_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1526046932_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1526046932_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@46a16298
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1526046932_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 843; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214296(104857184); length = 101/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1526046932_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1526046932_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1526046932_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1526046932_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4b0871ff
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@774de96a
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1526046932_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1526046932_0001_m_000000_0 decomp: 897 len: 901 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 897 bytes from map-output for attempt_local1526046932_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 897, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->897
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 871 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 897 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 901 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 871 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1526046932_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1526046932_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1526046932_0001_r_000000_0' to hdfs://node01:8020/out/_temporary/0/task_local1526046932_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1526046932_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1526046932_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1526046932_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=2278
		FILE: Number of bytes written=603907
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=843
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=26
		Map output records=26
		Map output bytes=843
		Map output materialized bytes=901
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=26
		Reduce shuffle bytes=901
		Reduce input records=26
		Reduce output records=26
		Spilled Records=52
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=11
		Total committed heap usage (bytes)=479723520
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=843
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1239790961_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1239790961_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1239790961_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3c632153
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1239790961_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1207; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214296(104857184); length = 101/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1239790961_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1239790961_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1239790961_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1239790961_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@62b5276f
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@708f4e61
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1239790961_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1239790961_0001_m_000000_0 decomp: 1261 len: 1265 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1261 bytes from map-output for attempt_local1239790961_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1261, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1261
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1221 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1261 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1265 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1221 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1239790961_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1239790961_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1239790961_0001_r_000000_0' to hdfs://node01:8020/out/_temporary/0/task_local1239790961_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1239790961_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1239790961_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1239790961_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=3006
		FILE: Number of bytes written=604999
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=1207
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=26
		Map output records=26
		Map output bytes=1207
		Map output materialized bytes=1265
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=26
		Reduce shuffle bytes=1265
		Reduce input records=26
		Reduce output records=26
		Spilled Records=52
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=543162368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=1207
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local827298638_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local827298638_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local827298638_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@545ebfad
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local827298638_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1207; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214296(104857184); length = 101/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local827298638_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local827298638_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local827298638_0001_m_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local827298638_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4b0871ff
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@774de96a
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local827298638_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local827298638_0001_m_000000_0 decomp: 1261 len: 1265 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1261 bytes from map-output for attempt_local827298638_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1261, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1261
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1221 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1261 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1265 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1221 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local827298638_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local827298638_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local827298638_0001_r_000000_0' to hdfs://node01:8020/out/_temporary/0/task_local827298638_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local827298638_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local827298638_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local827298638_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=3006
		FILE: Number of bytes written=601907
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1917952
		HDFS: Number of bytes written=1207
		HDFS: Number of read operations=15
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
	Map-Reduce Framework
		Map input records=26
		Map output records=26
		Map output bytes=1207
		Map output materialized bytes=1265
		Input split bytes=154
		Combine input records=0
		Combine output records=0
		Reduce input groups=26
		Reduce shuffle bytes=1265
		Reduce input records=26
		Reduce output records=26
		Spilled Records=52
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=13
		Total committed heap usage (bytes)=479199232
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=958976
	File Output Format Counters 
		Bytes Written=1207
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 2
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1226403321_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1226403321_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1226403321_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@74a63bda
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1226403321_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1207; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214296(104857184); length = 101/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1226403321_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1226403321_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1226403321_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1226403321_0001_m_000001_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7db822cf
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/exportcampaigndata-2.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1207; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214296(104857184); length = 101/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1226403321_0001_m_000001_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1226403321_0001_m_000001_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1226403321_0001_m_000001_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1226403321_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@34596e80
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@c2d7c39
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1226403321_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1226403321_0001_m_000001_0 decomp: 1261 len: 1265 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1261 bytes from map-output for attempt_local1226403321_0001_m_000001_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1261, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1261
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1226403321_0001_m_000000_0 decomp: 1261 len: 1265 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1261 bytes from map-output for attempt_local1226403321_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1261, inMemoryMapOutputs.size() -> 2, commitMemory -> 1261, usedMemory ->2522
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 2442 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 2522 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 2524 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 2480 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1226403321_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1226403321_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1226403321_0001_r_000000_0' to hdfs://node01:8020/out/_temporary/0/task_local1226403321_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1226403321_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1226403321_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1226403321_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=6904
		FILE: Number of bytes written=911217
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4794880
		HDFS: Number of bytes written=1207
		HDFS: Number of read operations=25
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=8
	Map-Reduce Framework
		Map input records=52
		Map output records=52
		Map output bytes=2414
		Map output materialized bytes=2530
		Input split bytes=292
		Combine input records=0
		Combine output records=0
		Reduce input groups=26
		Reduce shuffle bytes=2530
		Reduce input records=52
		Reduce output records=26
		Spilled Records=104
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=41
		Total committed heap usage (bytes)=1078460416
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1917952
	File Output Format Counters 
		Bytes Written=1207
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 2
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local712330888_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local712330888_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local712330888_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7647dbc6
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local712330888_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1207; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214296(104857184); length = 101/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local712330888_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local712330888_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local712330888_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local712330888_0001_m_000001_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7c5d0811
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/exportcampaigndata-2.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1207; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214296(104857184); length = 101/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local712330888_0001_m_000001_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local712330888_0001_m_000001_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local712330888_0001_m_000001_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local712330888_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1b853b3f
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7c66b019
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local712330888_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local712330888_0001_m_000001_0 decomp: 1261 len: 1265 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1261 bytes from map-output for attempt_local712330888_0001_m_000001_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1261, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1261
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local712330888_0001_m_000000_0 decomp: 1261 len: 1265 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1261 bytes from map-output for attempt_local712330888_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1261, inMemoryMapOutputs.size() -> 2, commitMemory -> 1261, usedMemory ->2522
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 2442 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 2522 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 2524 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 2480 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local712330888_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local712330888_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local712330888_0001_r_000000_0' to hdfs://node01:8020/out/_temporary/0/task_local712330888_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local712330888_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local712330888_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local712330888_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=6904
		FILE: Number of bytes written=905169
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4794880
		HDFS: Number of bytes written=2414
		HDFS: Number of read operations=25
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=8
	Map-Reduce Framework
		Map input records=52
		Map output records=52
		Map output bytes=2414
		Map output materialized bytes=2530
		Input split bytes=292
		Combine input records=0
		Combine output records=0
		Reduce input groups=26
		Reduce shuffle bytes=2530
		Reduce input records=52
		Reduce output records=52
		Spilled Records=104
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=11
		Total committed heap usage (bytes)=933756928
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1917952
	File Output Format Counters 
		Bytes Written=2414
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 2
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1677863163_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1677863163_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1677863163_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@48b6c580
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1677863163_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1207; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214296(104857184); length = 101/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1677863163_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1677863163_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1677863163_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1677863163_0001_m_000001_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4b9c3b7c
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/exportcampaigndata-2.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1207; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214296(104857184); length = 101/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1677863163_0001_m_000001_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1677863163_0001_m_000001_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1677863163_0001_m_000001_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1677863163_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5e1b2735
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5f269763
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1677863163_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1677863163_0001_m_000001_0 decomp: 1261 len: 1265 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1261 bytes from map-output for attempt_local1677863163_0001_m_000001_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1261, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1261
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1677863163_0001_m_000000_0 decomp: 1261 len: 1265 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1261 bytes from map-output for attempt_local1677863163_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1261, inMemoryMapOutputs.size() -> 2, commitMemory -> 1261, usedMemory ->2522
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 2442 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 2522 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 2524 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 2480 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1677863163_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1677863163_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1677863163_0001_r_000000_0' to hdfs://node01:8020/out/_temporary/0/task_local1677863163_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1677863163_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1677863163_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1677863163_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=6904
		FILE: Number of bytes written=909801
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4794880
		HDFS: Number of bytes written=2414
		HDFS: Number of read operations=25
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=8
	Map-Reduce Framework
		Map input records=52
		Map output records=52
		Map output bytes=2414
		Map output materialized bytes=2530
		Input split bytes=292
		Combine input records=0
		Combine output records=0
		Reduce input groups=26
		Reduce shuffle bytes=2530
		Reduce input records=52
		Reduce output records=52
		Spilled Records=104
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=16
		Total committed heap usage (bytes)=1078984704
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1917952
	File Output Format Counters 
		Bytes Written=2414
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 2
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local2001025429_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local2001025429_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local2001025429_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@215f3216
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local2001025429_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1207; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214296(104857184); length = 101/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local2001025429_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local2001025429_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local2001025429_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local2001025429_0001_m_000001_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3e5ba81a
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/exportcampaigndata-2.xls:0+958976
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1207; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214296(104857184); length = 101/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local2001025429_0001_m_000001_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local2001025429_0001_m_000001_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local2001025429_0001_m_000001_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local2001025429_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@b652f63
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@9047c2a
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local2001025429_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local2001025429_0001_m_000000_0 decomp: 1261 len: 1265 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1261 bytes from map-output for attempt_local2001025429_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1261, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1261
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local2001025429_0001_m_000001_0 decomp: 1261 len: 1265 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1261 bytes from map-output for attempt_local2001025429_0001_m_000001_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1261, inMemoryMapOutputs.size() -> 2, commitMemory -> 1261, usedMemory ->2522
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 2442 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 2522 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 2524 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 2480 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local2001025429_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local2001025429_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local2001025429_0001_r_000000_0' to hdfs://node01:8020/out/_temporary/0/task_local2001025429_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local2001025429_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local2001025429_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local2001025429_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=6904
		FILE: Number of bytes written=909639
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4794880
		HDFS: Number of bytes written=2414
		HDFS: Number of read operations=25
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=8
	Map-Reduce Framework
		Map input records=52
		Map output records=52
		Map output bytes=2414
		Map output materialized bytes=2530
		Input split bytes=292
		Combine input records=0
		Combine output records=0
		Reduce input groups=26
		Reduce shuffle bytes=2530
		Reduce input records=52
		Reduce output records=52
		Spilled Records=104
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=11
		Total committed heap usage (bytes)=930611200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1917952
	File Output Format Counters 
		Bytes Written=2414
 INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
 INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
 WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
 INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 2
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
 INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1482508378_0001
 INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
 INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1482508378_0001
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
 INFO Thread-4 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1482508378_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@48b6c580
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/d03620a5-808c-4c58-b91e-5853911de936.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1482508378_0001 running in uber mode : false
 INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1207; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214296(104857184); length = 101/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1482508378_0001_m_000000_0 is done. And is in the process of committing
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1482508378_0001_m_000000_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1482508378_0001_m_000000_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1482508378_0001_m_000001_0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7a53f350
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://node01:8020/huohua/ods_rawdata/2018-11-13/exportcampaigndata-2.xls:0+958976
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1207; bufvoid = 104857600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214296(104857184); length = 101/6553600
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1482508378_0001_m_000001_0 is done. And is in the process of committing
 INFO main org.apache.hadoop.mapreduce.Job -  map 50% reduce 0%
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1482508378_0001_m_000001_0' done.
 INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1482508378_0001_m_000001_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1482508378_0001_r_000000_0
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO pool-6-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2299825a
 INFO pool-6-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2dfa427a
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1315333760, maxSingleShuffleLimit=328833440, mergeThreshold=868120320, ioSortFactor=10, memToMemMergeOutputsThreshold=10
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1482508378_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1482508378_0001_m_000001_0 decomp: 1261 len: 1265 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1261 bytes from map-output for attempt_local1482508378_0001_m_000001_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1261, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1261
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1482508378_0001_m_000000_0 decomp: 1261 len: 1265 to MEMORY
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1261 bytes from map-output for attempt_local1482508378_0001_m_000000_0
 INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1261, inMemoryMapOutputs.size() -> 2, commitMemory -> 1261, usedMemory ->2522
 INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 2442 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 2522 bytes to disk to satisfy reduce memory limit
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 2524 bytes from disk
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 2480 bytes
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
 INFO pool-6-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1482508378_0001_r_000000_0 is done. And is in the process of committing
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1482508378_0001_r_000000_0 is allowed to commit now
 INFO pool-6-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1482508378_0001_r_000000_0' to hdfs://node01:8020/out/_temporary/0/task_local1482508378_0001_r_000000
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
 INFO pool-6-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1482508378_0001_r_000000_0' done.
 INFO pool-6-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1482508378_0001_r_000000_0
 INFO Thread-4 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
 INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
 INFO main org.apache.hadoop.mapreduce.Job - Job job_local1482508378_0001 completed successfully
 INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=6904
		FILE: Number of bytes written=909639
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4794880
		HDFS: Number of bytes written=2414
		HDFS: Number of read operations=25
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=8
	Map-Reduce Framework
		Map input records=52
		Map output records=52
		Map output bytes=2414
		Map output materialized bytes=2530
		Input split bytes=292
		Combine input records=0
		Combine output records=0
		Reduce input groups=26
		Reduce shuffle bytes=2530
		Reduce input records=52
		Reduce output records=52
		Spilled Records=104
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=13
		Total committed heap usage (bytes)=942669824
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1917952
	File Output Format Counters 
		Bytes Written=2414
 